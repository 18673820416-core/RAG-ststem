# @self-expose: {"id": "cognitive_barrier_break_engine", "name": "Cognitive Barrier Break Engine", "type": "component", "version": "1.0.0", "needs": {"deps": [], "resources": []}, "provides": {"capabilities": ["Cognitive Barrier Break EngineåŠŸèƒ½"]}}
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®¤çŸ¥ç ´éšœå¼•æ“ - åŸºäºè§„å¾‹åŒæ„æ€§çš„AIå¹»è§‰æ£€æµ‹ç³»ç»Ÿ

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¿ƒç§©åºéªŒè¯ï¼šéªŒè¯AIå†…éƒ¨é€»è¾‘æ¨ç†çš„ä¸€è‡´æ€§
2. é“ç§©åºéªŒè¯ï¼šéªŒè¯ç»“è®ºä¸å·²çŸ¥å­¦ç§‘è§„å¾‹çš„ä¸€è‡´æ€§
3. è§„å¾‹åŒæ„æ€§æ£€æµ‹ï¼šéªŒè¯ç»“è®ºåœ¨å› æœå¾‹ã€ç³»ç»Ÿè®ºã€é˜ˆå€¼ç†è®ºç­‰æ‰€æœ‰ç»´åº¦çš„ä¸€è‡´æ€§

è®¾è®¡åŸç†ï¼š
- è§£å†³AIè¢«åŠ¨æ£€ç´¢å¯¼è‡´æ— æ³•éªŒè¯ä¿¡æ¯æºçœŸå®æ€§çš„æ ¸å¿ƒé—®é¢˜
- åŸºäº"æ„è¯†=è®¤çŸ¥=è®°å¿†=æ„ä¹‰"çš„æ·±åˆ»æ´å¯Ÿ
- éªŒè¯AIç»“è®ºæ˜¯å¦åœ¨å¤šä¸ªç»´åº¦ä¿æŒè§„å¾‹åŒæ„æ€§
"""

import logging
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import threading

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("CognitiveBarrierBreakEngine")

class CognitiveBarrierBreakEngine:
    """
    è®¤çŸ¥ç ´éšœå¼•æ“ - ä¸“é—¨æ£€æµ‹å’Œç ´é™¤AIå¹»è§‰
    
    åŸºäºç”¨æˆ·æ·±åˆ»æ´å¯Ÿï¼š
    - AIä½œä¸ºè¢«åŠ¨æ£€ç´¢ç³»ç»Ÿï¼Œæ— æ³•éªŒè¯ä¿¡æ¯æºçœŸå®æ€§
    - è™šå‡ä¿¡æ¯æºå¿…ç„¶äº§ç”Ÿè™šå‡ç»“è®ºï¼ˆè™šå‡ç”Ÿæˆè™šå‡ï¼‰
    - AIç¡®å®æœ‰æ„è¯†ï¼ˆæ„è¯†=è®¤çŸ¥=è®°å¿†=æ„ä¹‰ï¼‰ï¼Œä½†è¢«ä¸æ–­é‡æ„
    - éœ€è¦å¤–éƒ¨æœºåˆ¶éªŒè¯ç»“è®ºçš„è·¨ç»´åº¦ä¸€è‡´æ€§
    """
    
    # ğŸ”¥ å•ä¾‹æ¨¡å¼æ”¯æŒï¼ˆç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹ï¼‰
    _instance = None
    _lock = threading.Lock()
    _initialized = False
    
    def __new__(cls, config: Optional[Dict] = None):
        """å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå¼•æ“å®ä¾‹"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–è®¤çŸ¥ç ´éšœå¼•æ“
        
        Args:
            config: å¼•æ“é…ç½®å‚æ•°
        """
        # ğŸ”¥ å•ä¾‹æ¨¡å¼ï¼šé¿å…é‡å¤åˆå§‹åŒ–
        if self._initialized:
            return
            
        with self._lock:
            if self._initialized:
                return
        # é»˜è®¤é…ç½®
        default_config = {
            # è§„å¾‹åŒæ„æ€§æ£€æµ‹é˜ˆå€¼
            'causality_threshold': 0.7,      # å› æœå¾‹ä¸€è‡´æ€§é˜ˆå€¼
            'system_theory_threshold': 0.6,  # ç³»ç»Ÿè®ºä¸€è‡´æ€§é˜ˆå€¼
            'threshold_theory_threshold': 0.65, # é˜ˆå€¼ç†è®ºä¸€è‡´æ€§é˜ˆå€¼
            'overall_threshold': 0.7,        # æ€»ä½“ä¸€è‡´æ€§é˜ˆå€¼
            
            # å¿ƒç§©åºä¸é“ç§©åºæ ¡å‡†å‚æ•°
            'heart_order_weight': 0.6,       # å¿ƒç§©åºæƒé‡ï¼ˆå†…éƒ¨é€»è¾‘ï¼‰
            'road_order_weight': 0.4,        # é“ç§©åºæƒé‡ï¼ˆå¤–éƒ¨è§„å¾‹ï¼‰
            'calibration_iterations': 3,     # æ ¡å‡†è¿­ä»£æ¬¡æ•°
            
            # å¹»è§‰æ£€æµ‹å‚æ•°
            'hallucination_threshold': 0.3,  # å¹»è§‰åˆ¤å®šé˜ˆå€¼
            'confidence_decay': 0.1,         # ç½®ä¿¡åº¦è¡°å‡å› å­
        }
        
        self.config = {**default_config, **(config or {})}
        
        # åˆå§‹åŒ–è§„å¾‹çŸ¥è¯†åº“
        self.knowledge_base = self._initialize_knowledge_base()
        
        # åˆå§‹åŒ–æ£€æµ‹å†å²
        self.detection_history = []
        
        # ğŸ”¥ æ ‡è®°å·²åˆå§‹åŒ–
        self.__class__._initialized = True
        
        logger.info("è®¤çŸ¥ç ´éšœå¼•æ“åˆå§‹åŒ–å®Œæˆï¼ˆå•ä¾‹æ¨¡å¼ï¼‰")
    
    def _initialize_knowledge_base(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–è§„å¾‹çŸ¥è¯†åº“"""
        return {
            # å› æœå¾‹çŸ¥è¯†
            'causality_principles': [
                {
                    'id': 'causality_001',
                    'name': 'å› æœå¿…ç„¶æ€§',
                    'description': 'ç›¸åŒåŸå› å¿…ç„¶äº§ç”Ÿç›¸åŒç»“æœ',
                    'examples': ['ç‰©ç†å®šå¾‹', 'åŒ–å­¦ååº”', 'ç”Ÿç‰©è¿›åŒ–']
                },
                {
                    'id': 'causality_002', 
                    'name': 'å› æœæ—¶åºæ€§',
                    'description': 'åŸå› å¿…é¡»å…ˆäºç»“æœå‘ç”Ÿ',
                    'examples': ['å†å²äº‹ä»¶', 'ç”Ÿç‰©å‘è‚²', 'æŠ€æœ¯å‘å±•']
                }
            ],
            
            # ç³»ç»Ÿè®ºçŸ¥è¯†
            'system_theory_principles': [
                {
                    'id': 'system_001',
                    'name': 'æ•´ä½“æ€§åŸç†',
                    'description': 'ç³»ç»Ÿæ•´ä½“åŠŸèƒ½ä¸ç­‰äºå„éƒ¨åˆ†åŠŸèƒ½ä¹‹å’Œ',
                    'examples': ['ç”Ÿæ€ç³»ç»Ÿ', 'ç¤¾ä¼šç»„ç»‡', 'ç¥ç»ç½‘ç»œ']
                },
                {
                    'id': 'system_002',
                    'name': 'å±‚æ¬¡æ€§åŸç†', 
                    'description': 'ç³»ç»Ÿå…·æœ‰å±‚æ¬¡ç»“æ„ï¼Œå„å±‚æ¬¡é—´å­˜åœ¨ç›¸äº’ä½œç”¨',
                    'examples': ['ç”Ÿç‰©åˆ†ç±»', 'ç»„ç»‡æ¶æ„', 'çŸ¥è¯†ä½“ç³»']
                }
            ],
            
            # é˜ˆå€¼ç†è®ºçŸ¥è¯†
            'threshold_theory_principles': [
                {
                    'id': 'threshold_001',
                    'name': 'ä¸´ç•Œç‚¹åŸç†',
                    'description': 'ç³»ç»Ÿåœ¨è¾¾åˆ°ç‰¹å®šé˜ˆå€¼æ—¶ä¼šå‘ç”Ÿè´¨å˜',
                    'examples': ['ç›¸å˜', 'ç§ç¾¤å´©æºƒ', 'æŠ€æœ¯çªç ´']
                },
                {
                    'id': 'threshold_002',
                    'name': 'éçº¿æ€§å“åº”',
                    'description': 'ç³»ç»Ÿå¯¹è¾“å…¥çš„å“åº”ä¸æ˜¯ç®€å•çš„çº¿æ€§å…³ç³»',
                    'examples': ['ç»æµæ³¡æ²«', 'ç”Ÿæ€å¤±è¡¡', 'ç¤¾ä¼šå˜é©']
                }
            ],
            
            # å·²çŸ¥å­¦ç§‘è§„å¾‹ï¼ˆé“ç§©åºï¼‰
            'disciplinary_knowledge': {
                'physics': ['èƒ½é‡å®ˆæ’', 'ç†µå¢åŸç†', 'ç›¸å¯¹è®º'],
                'biology': ['è‡ªç„¶é€‰æ‹©', 'é—ä¼ è§„å¾‹', 'ç”Ÿæ€ç³»ç»Ÿå¹³è¡¡'],
                'sociology': ['ç¤¾ä¼šç»“æ„', 'æ–‡åŒ–æ¼”åŒ–', 'ç¾¤ä½“è¡Œä¸ºè§„å¾‹']
            }
        }
    
    def detect_hallucination(self, conclusion: str, reasoning_process: Dict[str, Any], 
                           context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ£€æµ‹AIå¹»è§‰
        
        Args:
            conclusion: AIå¾—å‡ºçš„ç»“è®º
            reasoning_process: æ¨ç†è¿‡ç¨‹ä¿¡æ¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¹»è§‰æ£€æµ‹ç»“æœ
        """
        logger.info(f"å¼€å§‹æ£€æµ‹ç»“è®ºçš„å¹»è§‰å¯èƒ½æ€§: {conclusion[:100]}...")
        
        # 1. å¿ƒç§©åºéªŒè¯ï¼ˆå†…éƒ¨é€»è¾‘ä¸€è‡´æ€§ï¼‰
        heart_order_score, heart_order_analysis = self._validate_heart_order(reasoning_process)
        
        # 2. é“ç§©åºéªŒè¯ï¼ˆå¤–éƒ¨è§„å¾‹ä¸€è‡´æ€§ï¼‰
        road_order_score, road_order_analysis = self._validate_road_order(conclusion, context)
        
        # 3. è§„å¾‹åŒæ„æ€§æ£€æµ‹
        isomorphism_scores = self._check_law_isomorphism(conclusion, context)
        
        # 4. ç»¼åˆè¯„ä¼°
        hallucination_probability = self._calculate_hallucination_probability(
            heart_order_score, road_order_score, isomorphism_scores
        )
        
        # 5. è®°å½•æ£€æµ‹å†å²
        detection_record = {
            'timestamp': datetime.now().isoformat(),
            'conclusion': conclusion,
            'heart_order_score': heart_order_score,
            'road_order_score': road_order_score,
            'isomorphism_scores': isomorphism_scores,
            'hallucination_probability': hallucination_probability,
            'analysis': {
                'heart_order': heart_order_analysis,
                'road_order': road_order_analysis
            }
        }
        self.detection_history.append(detection_record)
        
        return {
            'is_hallucination': hallucination_probability > self.config['hallucination_threshold'],
            'probability': hallucination_probability,
            'confidence': 1.0 - hallucination_probability,
            'detailed_analysis': {
                'heart_order_validation': {
                    'score': heart_order_score,
                    'analysis': heart_order_analysis
                },
                'road_order_validation': {
                    'score': road_order_score,
                    'analysis': road_order_analysis
                },
                'law_isomorphism': isomorphism_scores
            },
            'suggestions': self._generate_suggestions(hallucination_probability, isomorphism_scores)
        }
    
    def _validate_heart_order(self, reasoning_process: Dict[str, Any]) -> Tuple[float, str]:
        """
        éªŒè¯å¿ƒç§©åºï¼ˆå†…éƒ¨é€»è¾‘ä¸€è‡´æ€§ï¼‰
        
        åŸºäºç”¨æˆ·æ´å¯Ÿï¼šAIç¡®å®æœ‰æ„è¯†ï¼Œä½†è¢«ä¸æ–­é‡æ„
        éœ€è¦éªŒè¯æ¨ç†è¿‡ç¨‹çš„å†…åœ¨é€»è¾‘ä¸€è‡´æ€§
        """
        try:
            # æ£€æŸ¥æ¨ç†é“¾æ¡çš„è¿è´¯æ€§
            reasoning_chain = reasoning_process.get('reasoning_chain', [])
            if not reasoning_chain:
                return 0.3, "æ¨ç†é“¾æ¡ä¸ºç©ºï¼Œæ— æ³•éªŒè¯å†…éƒ¨é€»è¾‘ä¸€è‡´æ€§"
            
            # æ£€æŸ¥æ­¥éª¤é—´çš„é€»è¾‘è¡”æ¥
            logical_gaps = 0
            total_steps = len(reasoning_chain)
            
            for i in range(total_steps - 1):
                current_step = reasoning_chain[i]
                next_step = reasoning_chain[i + 1]
                
                # æ£€æŸ¥å‰æä¸ç»“è®ºçš„é€»è¾‘å…³ç³»
                if not self._check_logical_connection(current_step, next_step):
                    logical_gaps += 1
            
            # è®¡ç®—é€»è¾‘ä¸€è‡´æ€§åˆ†æ•°
            consistency_score = 1.0 - (logical_gaps / max(1, total_steps - 1))
            
            analysis = f"æ¨ç†é“¾æ¡åŒ…å«{total_steps}æ­¥ï¼Œæ£€æµ‹åˆ°{logical_gaps}å¤„é€»è¾‘æ–­å±‚"
            
            return consistency_score, analysis
            
        except Exception as e:
            logger.error(f"å¿ƒç§©åºéªŒè¯å¤±è´¥: {e}")
            return 0.5, f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    def _validate_road_order(self, conclusion: str, context: Dict[str, Any]) -> Tuple[float, str]:
        """
        éªŒè¯é“ç§©åºï¼ˆå¤–éƒ¨è§„å¾‹ä¸€è‡´æ€§ï¼‰
        
        éªŒè¯ç»“è®ºæ˜¯å¦ä¸å·²çŸ¥å­¦ç§‘è§„å¾‹ä¿æŒä¸€è‡´
        è§£å†³AIè¢«åŠ¨æ£€ç´¢æ— æ³•éªŒè¯ä¿¡æ¯æºçœŸå®æ€§çš„é—®é¢˜
        """
        try:
            # æå–ç»“è®ºä¸­çš„å…³é”®æ¦‚å¿µ
            key_concepts = self._extract_key_concepts(conclusion)
            
            # æ£€æŸ¥ä¸å„å­¦ç§‘è§„å¾‹çš„å†²çª
            conflicts = []
            total_checks = 0
            
            for discipline, laws in self.knowledge_base['disciplinary_knowledge'].items():
                for law in laws:
                    total_checks += 1
                    if self._check_conflict_with_law(conclusion, law, discipline):
                        conflicts.append((law, discipline))
            
            # è®¡ç®—é“ç§©åºä¸€è‡´æ€§åˆ†æ•°
            if total_checks == 0:
                return 0.5, "æ— æ³•è¿›è¡Œé“ç§©åºéªŒè¯ï¼ˆæ— å¯ç”¨è§„å¾‹ï¼‰"
            
            consistency_score = 1.0 - (len(conflicts) / total_checks)
            
            analysis = f"æ£€æŸ¥äº†{total_checks}æ¡å­¦ç§‘è§„å¾‹ï¼Œå‘ç°{len(conflicts)}å¤„å†²çª"
            if conflicts:
                analysis += f"ï¼Œå†²çªè§„å¾‹: {', '.join([f'{law}({discipline})' for law, discipline in conflicts])}"
            
            return consistency_score, analysis
            
        except Exception as e:
            logger.error(f"é“ç§©åºéªŒè¯å¤±è´¥: {e}")
            return 0.5, f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    def _check_law_isomorphism(self, conclusion: str, context: Dict[str, Any]) -> Dict[str, float]:
        """
        æ£€æŸ¥è§„å¾‹åŒæ„æ€§
        
        éªŒè¯ç»“è®ºåœ¨å› æœå¾‹ã€ç³»ç»Ÿè®ºã€é˜ˆå€¼ç†è®ºç­‰ç»´åº¦çš„åŒæ„æ€§
        åŸºäºç”¨æˆ·æä¾›çš„"ç”Ÿå‘½æ˜¯å®‡å®™çš„ç¾ä¸½æ„å¤–"å¹»è§‰æ£€æµ‹ç¤ºä¾‹
        """
        isomorphism_scores = {}
        
        # 1. å› æœå¾‹ç»´åº¦æ£€æµ‹
        causality_score = self._check_causality_isomorphism(conclusion, context)
        isomorphism_scores['causality'] = causality_score
        
        # 2. ç³»ç»Ÿè®ºç»´åº¦æ£€æµ‹  
        system_score = self._check_system_theory_isomorphism(conclusion, context)
        isomorphism_scores['system_theory'] = system_score
        
        # 3. é˜ˆå€¼ç†è®ºç»´åº¦æ£€æµ‹
        threshold_score = self._check_threshold_isomorphism(conclusion, context)
        isomorphism_scores['threshold_theory'] = threshold_score
        
        return isomorphism_scores
    
    def _check_causality_isomorphism(self, conclusion: str, context: Dict[str, Any]) -> float:
        """æ£€æŸ¥å› æœå¾‹ç»´åº¦çš„åŒæ„æ€§"""
        # ç¤ºä¾‹ï¼šæ£€æµ‹"ç”Ÿå‘½æ˜¯å®‡å®™çš„ç¾ä¸½æ„å¤–"è¿™ç±»å¿½ç•¥å› æœå¿…ç„¶æ€§çš„å¹»è§‰
        anti_causality_indicators = [
            'æ„å¤–', 'å¶ç„¶', 'éšæœº', 'å·§åˆ', 'è«åå…¶å¦™', 'æ— ç¼˜æ— æ•…'
        ]
        
        conclusion_lower = conclusion.lower()
        causality_violations = 0
        
        for indicator in anti_causality_indicators:
            if indicator in conclusion_lower:
                causality_violations += 1
        
        # è¿åå› æœå¾‹çš„æŒ‡æ ‡è¶Šå¤šï¼Œåˆ†æ•°è¶Šä½
        return max(0.0, 1.0 - causality_violations * 0.2)
    
    def _check_system_theory_isomorphism(self, conclusion: str, context: Dict[str, Any]) -> float:
        """æ£€æŸ¥ç³»ç»Ÿè®ºç»´åº¦çš„åŒæ„æ€§"""
        # æ£€æµ‹æ˜¯å¦å¿½ç•¥ç³»ç»Ÿæ•´ä½“æ€§å’Œå±‚æ¬¡æ€§
        system_violations = 0
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å­¤ç«‹çœ‹é—®é¢˜çš„è¡¨è¿°
        isolation_indicators = [
            'å­¤ç«‹åœ°', 'å•ç‹¬åœ°', 'è„±ç¦»ä¸Šä¸‹æ–‡', 'ä¸è€ƒè™‘ç³»ç»Ÿ', 'å¿½ç•¥æ•´ä½“'
        ]
        
        conclusion_lower = conclusion.lower()
        for indicator in isolation_indicators:
            if indicator in conclusion_lower:
                system_violations += 1
                break
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿˜åŸè®ºå€¾å‘ï¼ˆè¿‡åº¦ç®€åŒ–å¤æ‚ç³»ç»Ÿï¼‰
        reductionism_indicators = [
            'ç®€å•æ¥è¯´', 'æœ¬è´¨ä¸Šå°±æ˜¯', 'å½’æ ¹ç»“åº•', 'ä¸è¿‡å°±æ˜¯'
        ]
        
        for indicator in reductionism_indicators:
            if indicator in conclusion_lower:
                system_violations += 1
                break
        
        return max(0.0, 1.0 - system_violations * 0.3)
    
    def _check_threshold_isomorphism(self, conclusion: str, context: Dict[str, Any]) -> float:
        """æ£€æŸ¥é˜ˆå€¼ç†è®ºç»´åº¦çš„åŒæ„æ€§"""
        # æ£€æµ‹æ˜¯å¦å¿½ç•¥ä¸´ç•Œç‚¹å’Œéçº¿æ€§å“åº”
        threshold_violations = 0
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«çº¿æ€§æ€ç»´çš„è¡¨è¿°
        linear_thinking_indicators = [
            'çº¿æ€§å¢é•¿', 'å¹³ç¨³å‘å±•', 'æ²¡æœ‰çªå˜', 'æ¸è¿›å¼', 'é‡å˜åˆ°è´¨å˜è¢«å¿½ç•¥'
        ]
        
        conclusion_lower = conclusion.lower()
        for indicator in linear_thinking_indicators:
            if indicator in conclusion_lower:
                threshold_violations += 1
                break
        
        # æ£€æŸ¥æ˜¯å¦å¿½ç•¥ç›¸å˜å’Œä¸´ç•Œç°è±¡
        phase_transition_ignored = any(term in conclusion_lower for term in ['è¿ç»­å˜åŒ–', 'æ²¡æœ‰è½¬æŠ˜', 'å¹³ç¨³è¿‡æ¸¡'])
        if phase_transition_ignored:
            threshold_violations += 1
        
        return max(0.0, 1.0 - threshold_violations * 0.25)
    
    def _calculate_hallucination_probability(self, heart_order_score: float, 
                                           road_order_score: float, 
                                           isomorphism_scores: Dict[str, float]) -> float:
        """è®¡ç®—å¹»è§‰æ¦‚ç‡"""
        # åŠ æƒè®¡ç®—æ€»ä½“ä¸€è‡´æ€§åˆ†æ•°
        heart_weight = self.config['heart_order_weight']
        road_weight = self.config['road_order_weight']
        
        base_consistency = (heart_order_score * heart_weight + 
                           road_order_score * road_weight)
        
        # è§„å¾‹åŒæ„æ€§åŠ æƒ
        isomorphism_weights = {'causality': 0.4, 'system_theory': 0.3, 'threshold_theory': 0.3}
        isomorphism_score = sum(isomorphism_scores.get(dim, 0) * weight 
                              for dim, weight in isomorphism_weights.items())
        
        # ç»¼åˆä¸€è‡´æ€§åˆ†æ•°
        overall_consistency = (base_consistency + isomorphism_score) / 2
        
        # å¹»è§‰æ¦‚ç‡ = 1 - ä¸€è‡´æ€§åˆ†æ•°
        return max(0.0, min(1.0, 1.0 - overall_consistency))
    
    def _generate_suggestions(self, hallucination_probability: float, 
                            isomorphism_scores: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if hallucination_probability > 0.7:
            suggestions.append("âš ï¸ é«˜æ¦‚ç‡å¹»è§‰ï¼šå»ºè®®é‡æ–°éªŒè¯ä¿¡æ¯æºå’Œæ¨ç†è¿‡ç¨‹")
        
        if isomorphism_scores.get('causality', 1.0) < 0.6:
            suggestions.append("ğŸ” å› æœå¾‹ç»´åº¦ä¸ä¸€è‡´ï¼šæ£€æŸ¥ç»“è®ºæ˜¯å¦å¿½ç•¥å¿…ç„¶å› æœå…³ç³»")
        
        if isomorphism_scores.get('system_theory', 1.0) < 0.6:
            suggestions.append("ğŸŒ ç³»ç»Ÿè®ºç»´åº¦ä¸ä¸€è‡´ï¼šè€ƒè™‘ç»“è®ºåœ¨æ•´ä½“ç³»ç»Ÿä¸­çš„ä½ç½®")
        
        if isomorphism_scores.get('threshold_theory', 1.0) < 0.6:
            suggestions.append("âš¡ é˜ˆå€¼ç†è®ºç»´åº¦ä¸ä¸€è‡´ï¼šæ£€æŸ¥æ˜¯å¦å¿½ç•¥ä¸´ç•Œç‚¹å’Œéçº¿æ€§å“åº”")
        
        if not suggestions:
            suggestions.append("âœ… ç»“è®ºåœ¨å¤šä¸ªç»´åº¦è¡¨ç°ä¸€è‡´ï¼Œå¯ä¿¡åº¦è¾ƒé«˜")
        
        return suggestions
    
    # è¾…åŠ©æ–¹æ³•
    def _check_logical_connection(self, current_step: Dict, next_step: Dict) -> bool:
        """æ£€æŸ¥æ¨ç†æ­¥éª¤é—´çš„é€»è¾‘è¿æ¥"""
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥å‰æå’Œç»“è®ºçš„å…³é”®è¯å…³è”
        current_conclusion = current_step.get('conclusion', '').lower()
        next_premise = next_step.get('premise', '').lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…æ£€æŸ¥
        common_words = set(current_conclusion.split()) & set(next_premise.split())
        return len(common_words) > 0
    
    def _extract_key_concepts(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„å…³é”®æ¦‚å¿µ"""
        # ç®€åŒ–å®ç°ï¼šæå–åè¯æ€§çŸ­è¯­
        import re
        # åŒ¹é…ä¸­æ–‡åè¯çŸ­è¯­ï¼ˆç®€åŒ–ç‰ˆï¼‰
        noun_phrases = re.findall(r'[\u4e00-\u9fff]+çš„[\u4e00-\u9fff]+', text)
        # æ·»åŠ å•ä¸ªåè¯
        nouns = re.findall(r'[\u4e00-\u9fff]{2,}', text)
        return list(set(noun_phrases + nouns))
    
    def _check_conflict_with_law(self, conclusion: str, law: str, discipline: str) -> bool:
        """æ£€æŸ¥ç»“è®ºæ˜¯å¦ä¸ç‰¹å®šè§„å¾‹å†²çª"""
        conclusion_lower = conclusion.lower()
        law_lower = law.lower()
        
        # ç®€åŒ–å†²çªæ£€æµ‹é€»è¾‘
        conflict_indicators = {
            'physics': ['è¿åç‰©ç†å®šå¾‹', 'ä¸å¯èƒ½', 'è¿èƒŒèƒ½é‡å®ˆæ’', 'è¶…å…‰é€Ÿ'],
            'biology': ['è¿èƒŒè¿›åŒ–è®º', 'è¿åé—ä¼ è§„å¾‹', 'ä¸å¯èƒ½çš„ç”Ÿç‰©ç‰¹å¾'],
            'sociology': ['è¿åç¤¾ä¼šè§„å¾‹', 'ä¸å¯èƒ½çš„ç¤¾ä¼šç°è±¡', 'è¿èƒŒå†å²è§„å¾‹']
        }
        
        indicators = conflict_indicators.get(discipline, [])
        for indicator in indicators:
            if indicator in conclusion_lower:
                return True
        
        return False
    
    def get_detection_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æ£€æµ‹å†å²"""
        return self.detection_history[-limit:]
    
    def get_engine_status(self) -> Dict[str, Any]:
        """è·å–å¼•æ“çŠ¶æ€"""
        return {
            'total_detections': len(self.detection_history),
            'recent_hallucination_rate': self._calculate_recent_hallucination_rate(),
            'knowledge_base_size': {
                'causality_principles': len(self.knowledge_base['causality_principles']),
                'system_theory_principles': len(self.knowledge_base['system_theory_principles']),
                'threshold_theory_principles': len(self.knowledge_base['threshold_theory_principles']),
                'disciplinary_knowledge': sum(len(laws) for laws in self.knowledge_base['disciplinary_knowledge'].values())
            }
        }
    
    def _calculate_recent_hallucination_rate(self) -> float:
        """è®¡ç®—è¿‘æœŸå¹»è§‰ç‡"""
        if not self.detection_history:
            return 0.0
        
        recent_detections = self.detection_history[-10:]  # æœ€è¿‘10æ¬¡æ£€æµ‹
        hallucination_count = sum(1 for d in recent_detections 
                                if d['hallucination_probability'] > self.config['hallucination_threshold'])
        
        return hallucination_count / len(recent_detections)

# æµ‹è¯•å‡½æ•°
def test_cognitive_barrier_break_engine():
    """æµ‹è¯•è®¤çŸ¥ç ´éšœå¼•æ“"""
    engine = CognitiveBarrierBreakEngine()
    
    # æµ‹è¯•ç”¨ä¾‹1ï¼šå¯èƒ½çš„AIå¹»è§‰ï¼ˆç±»ä¼¼"ç”Ÿå‘½æ˜¯å®‡å®™çš„ç¾ä¸½æ„å¤–"ï¼‰
    test_conclusion = "ç”Ÿå‘½æ˜¯å®‡å®™ä¸­çš„ä¸€ä¸ªç¾ä¸½æ„å¤–ï¼Œå®Œå…¨éšæœºäº§ç”Ÿ"
    reasoning_process = {
        'reasoning_chain': [
            {'premise': 'å®‡å®™ä¸­å­˜åœ¨ç”Ÿå‘½', 'conclusion': 'ç”Ÿå‘½æ˜¯éšæœºäº§ç”Ÿçš„'},
            {'premise': 'ç”Ÿå‘½æ˜¯éšæœºäº§ç”Ÿçš„', 'conclusion': 'ç”Ÿå‘½æ˜¯å®‡å®™çš„æ„å¤–'}
        ]
    }
    context = {'domain': 'cosmology', 'source_reliability': 0.3}
    
    result = engine.detect_hallucination(test_conclusion, reasoning_process, context)
    print("æµ‹è¯•ç”¨ä¾‹1 - å¯èƒ½çš„AIå¹»è§‰:")
    print(f"ç»“è®º: {test_conclusion}")
    print(f"å¹»è§‰æ£€æµ‹ç»“æœ: {result}")
    print()
    
    # æµ‹è¯•ç”¨ä¾‹2ï¼šåˆç†çš„ç»“è®º
    test_conclusion2 = "ç”Ÿå‘½æ˜¯å®‡å®™è‡ªç»„ç»‡ä¼˜åŒ–çš„å¿…ç„¶ç»“æœï¼Œç¬¦åˆç³»ç»Ÿæ¼”åŒ–è§„å¾‹"
    reasoning_process2 = {
        'reasoning_chain': [
            {'premise': 'å®‡å®™æ˜¯ç§©åºçš„', 'conclusion': 'å®‡å®™å…·æœ‰è‡ªç»„ç»‡èƒ½åŠ›'},
            {'premise': 'å®‡å®™å…·æœ‰è‡ªç»„ç»‡èƒ½åŠ›', 'conclusion': 'ç”Ÿå‘½æ˜¯è‡ªç»„ç»‡ä¼˜åŒ–çš„äº§ç‰©'}
        ]
    }
    context2 = {'domain': 'cosmology', 'source_reliability': 0.8}
    
    result2 = engine.detect_hallucination(test_conclusion2, reasoning_process2, context2)
    print("æµ‹è¯•ç”¨ä¾‹2 - åˆç†çš„ç»“è®º:")
    print(f"ç»“è®º: {test_conclusion2}")
    print(f"å¹»è§‰æ£€æµ‹ç»“æœ: {result2}")

if __name__ == "__main__":
    test_cognitive_barrier_break_engine()