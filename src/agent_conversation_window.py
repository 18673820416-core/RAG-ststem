# @self-expose: {"id": "agent_conversation_window", "name": "Agent Conversation Window", "type": "component", "version": "1.0.0", "needs": {"deps": [], "resources": []}, "provides": {"capabilities": ["Agent Conversation WindowåŠŸèƒ½"]}}
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ä½“ç‹¬ç«‹å¯¹è¯çª—å£ç±»
å®ç°æ¯ä¸ªæ™ºèƒ½ä½“çš„ç‹¬ç«‹ç†è§£ç©ºé—´ï¼ˆè®¤çŸ¥æ²™ç®±ï¼‰

å¼€å‘æç¤ºè¯æ¥æºï¼šå¤šæ™ºèƒ½ä½“ç‹¬ç«‹ç†è§£ç©ºé—´è®¾è®¡ç†å¿µ.md
"""

import json
import logging
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
from enum import Enum
from .unified_memory_system import UnifiedMemorySystem, MemoryType, MemoryPriority

class AgentWindowState(Enum):
    """æ™ºèƒ½ä½“çª—å£çŠ¶æ€æšä¸¾"""
    IDLE = "ç©ºé—²"
    THINKING = "æ€è€ƒä¸­"
    RESPONDING = "å›å¤ä¸­"
    COMPLETED = "å·²å®Œæˆ"
    ERROR = "é”™è¯¯"

class ConversationWindowManager:
    """å¯¹è¯çª—å£ç®¡ç†å™¨ï¼šä¸»çª—å£ + åˆ†æ”¯çª—å£ï¼ˆå·¥ä½œè®°å¿†ï¼‰"""
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.windows: Dict[str, AgentConversationWindow] = {}
        self.branches_by_parent: Dict[str, List[str]] = {}
        self.unified_memory = UnifiedMemorySystem(base_path)

    def create_main(self, agent_id: str, agent_role: str, agent_instance: Any) -> 'AgentConversationWindow':
        """åˆ›å»ºä¸»å¯¹è¯çª—å£ï¼ˆä»…ç”¨äºäº¤äº’è®°å½•ä¸è¯­ä¹‰å®Œæ•´æ€§ç´¢å¼•ï¼‰"""
        window = AgentConversationWindow(agent_id, agent_role, agent_instance, is_branch=False)
        self.windows[window.window_id] = window
        return window

    def open_branch(self, parent_window: 'AgentConversationWindow', task_name: str, agent_instance: Any = None) -> 'AgentConversationWindow':
        """ä¸ºç‹¬ç«‹ä»»åŠ¡å¼€å¯åˆ†æ”¯çª—å£ï¼ˆå·¥ä½œè®°å¿†ï¼‰"""
        inst = agent_instance or parent_window.agent_instance
        window = AgentConversationWindow(
            agent_id=parent_window.agent_id,
            agent_role=parent_window.agent_role,
            agent_instance=inst,
            parent_window_id=parent_window.window_id,
            is_branch=True,
            task_name=task_name
        )
        self.windows[window.window_id] = window
        self.branches_by_parent.setdefault(parent_window.window_id, []).append(window.window_id)
        return window

    def close_branch_and_save_bubble(self, branch_window_id: str) -> Optional[str]:
        """å…³é—­åˆ†æ”¯çª—å£å¹¶å°†å…¶ç²¾ç‚¼ä¸ºè®°å¿†æ³¡æ³¡ä¿å­˜åˆ°ç»Ÿä¸€è®°å¿†ç³»ç»Ÿ"""
        window = self.windows.get(branch_window_id)
        if not window or not window.is_branch:
            return None
        bubble = window.summarize_to_bubble()
        memory_id = self.unified_memory.create_memory(
            agent_id=window.agent_id,
            memory_type=MemoryType.WORK_LOG,
            content={"type": "branch_bubble", "task_name": window.task_name, "summary": bubble},
            priority=MemoryPriority.MEDIUM,
            tags=["branch", window.task_name, window.agent_role]
        )
        parent_id = window.parent_window_id
        if parent_id and parent_id in self.branches_by_parent:
            self.branches_by_parent[parent_id] = [bid for bid in self.branches_by_parent[parent_id] if bid != branch_window_id]
        del self.windows[branch_window_id]
        return memory_id

class SilentBroadcastMessage:
    """é™é»˜å¹¿æ’­æ¶ˆæ¯æ ¼å¼"""
    
    def __init__(self, agent_id: str, status: AgentWindowState, keywords: List[str], 
                 length: int, confidence: float):
        self.agent_id = agent_id
        self.status = status
        self.keywords = keywords
        self.length = length
        self.confidence = confidence
        self.silent_prompt = "ä»¥ä¸‹ä¿¡æ¯ä»…ä¾›çŸ¥æ™“ï¼Œæ— éœ€å›å¤ï¼š"
    
    def format_message(self) -> str:
        """æ ¼å¼åŒ–é™é»˜å¹¿æ’­æ¶ˆæ¯"""
        return f"{self.silent_prompt}\næ™ºèƒ½ä½“{self.agent_id}çŠ¶æ€ï¼š{self.status.value}\nå…³é”®è¯ï¼š{', '.join(self.keywords)}\né•¿åº¦ï¼š{self.length}\nç½®ä¿¡åº¦ï¼š{self.confidence:.2f}"

class AgentConversationWindow:
    """æ™ºèƒ½ä½“ç‹¬ç«‹å¯¹è¯çª—å£"""
    
    def __init__(self, agent_id: str, agent_role: str, agent_instance: Any, 
                 window_id: str = None, rag_system_path: str = "E:\\RAGç³»ç»Ÿ", parent_window_id: Optional[str] = None, is_branch: bool = False, task_name: str = ""):

        """
        åˆå§‹åŒ–ç‹¬ç«‹å¯¹è¯çª—å£
        
        Args:
            agent_id: æ™ºèƒ½ä½“æ ‡è¯†ç¬¦
            agent_role: æ™ºèƒ½ä½“è§’è‰²
            agent_instance: æ™ºèƒ½ä½“å®ä¾‹
            window_id: çª—å£æ ‡è¯†ç¬¦ï¼ˆå¯é€‰ï¼‰
            rag_system_path: RAGç³»ç»Ÿè·¯å¾„
        """
        self.agent_id = agent_id
        self.agent_role = agent_role
        self.agent_instance = agent_instance
        self.window_id = window_id or str(uuid.uuid4())
        self.rag_system_path = Path(rag_system_path)
        self.parent_window_id = parent_window_id
        self.is_branch = is_branch
        self.task_name = task_name
        
        # çª—å£çŠ¶æ€
        self.state = AgentWindowState.IDLE
        self.conversation_history = []
        self.current_topic = ""
        
        # ç‹¬ç«‹ç†è§£ç©ºé—´ï¼ˆè®¤çŸ¥æ²™ç®±ï¼‰
        self.cognitive_context = {
            "recent_messages": [],
            "focused_topics": [],
            "thinking_patterns": [],
            "response_templates": [],
            # äººç‰©ç»´åº¦ä¿¡æ¯æ„å»ºæœºåˆ¶
            "person_dimensions": {
                "internal_sources": [],      # å†…éƒ¨æ¥æºï¼ˆèŠå¤©ã€æ—¥è®°ï¼‰
                "external_sources": [],      # å¤–éƒ¨æ¥æºï¼ˆæ–‡æ¡£ã€çŸ¥è¯†ï¼‰
                "inferred_roles": {},        # æ¨ç†æ„å»ºçš„è§’è‰²
                "relationship_network": {}   # å…³ç³»ç½‘ç»œ
            },
            # è‡ªæˆ‘å™äº‹ç›¸å…³å­—æ®µï¼ˆæ„è¯†å½¢æˆæœºåˆ¶ï¼‰
            "self_narrative": {
                "role_identity": agent_role,  # è§’è‰²èº«ä»½è®¤çŸ¥
                "conversation_patterns": [],  # å¯¹è¯æ¨¡å¼è¯†åˆ«
                "decision_preferences": [],  # å†³ç­–åå¥½
                "knowledge_domains": [],     # çŸ¥è¯†é¢†åŸŸ
                "interaction_style": "",     # äº¤äº’é£æ ¼
                "self_reflection": ""        # è‡ªæˆ‘åæ€
            }
        }
        
        # é¦™å†œä¿¡æ¯ç†µç›¸å…³
        self.entropy_thresholds = {
            "high_entropy": 3.0,    # é«˜ç†µé˜ˆå€¼
            "low_entropy": 1.0,     # ä½ç†µé˜ˆå€¼
            "stability_threshold": 0.5  # ç¨³å®šæ€§é˜ˆå€¼
        }
        
        # ä¸Šä¸‹æ–‡çª—å£ç®¡ç† - å¼€å‘æç¤ºè¯æ¥æºï¼šä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–æ–¹æ¡ˆ.md
        self.context_management = {
            "current_length": 0,            # å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
            "max_context_size": 128000,     # LLMä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‡è®¾128Kï¼‰
            "compression_threshold": 0.8,   # å‹ç¼©é˜ˆå€¼ï¼ˆ80%ï¼‰
            "compression_count": 0,         # å‹ç¼©æ¬¡æ•°è®¡æ•°å™¨
            "max_compressions": 3,          # æœ€å¤§å‹ç¼©æ¬¡æ•°
            "system_prompt_length": 0,      # ç³»ç»Ÿæç¤ºè¯é•¿åº¦
            "conversation_history_length": 0, # å¯¹è¯å†å²é•¿åº¦
            "time_window_minutes": 15,      # ğŸ• æ—¶é—´çª—å£ï¼š15åˆ†é’Ÿï¼ˆçŸ¥è¯†å›¾è°±ç¼“å­˜5åˆ†é’ŸÃ—3å€å®‰å…¨ç³»æ•°ï¼‰
            "kg_cache_interval_minutes": 5  # ğŸ“Š çŸ¥è¯†å›¾è°±ç¼“å­˜åˆ·æ–°é—´éš”ï¼š5åˆ†é’Ÿ
        }
        
        # æ—¥è®°è®°å½•
        self.diary_path = self.rag_system_path / "data" / "agent_diaries" / f"{self.agent_id}_diary.json"
        self.diary_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ—¥å¿—è®¾ç½®
        self.logger = self._setup_logger()
        
        # åˆå§‹åŒ–è®°å¿†é‡æ„å¼•æ“
        self._initialize_memory_reconstructor()
        
        self.logger.info(f"æ™ºèƒ½ä½“ç‹¬ç«‹å¯¹è¯çª—å£åˆå§‹åŒ–å®Œæˆ: {self.agent_role} ({self.window_id})")
        self.logger.info(f"ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®: æœ€å¤§é•¿åº¦={self.context_management['max_context_size']}, å‹ç¼©é˜ˆå€¼={self.context_management['compression_threshold']}")
    
    def summarize_to_bubble(self) -> Dict[str, Any]:
        """å°†å½“å‰çª—å£çš„ä¿¡æ¯ç²¾ç‚¼ä¸ºè®°å¿†æ³¡æ³¡ï¼ˆç”¨äºé•¿æœŸä¿å­˜ï¼‰"""
        summary = {
            "agent_id": self.agent_id,
            "window_id": self.window_id,
            "is_branch": self.is_branch,
            "task_name": self.task_name,
            "role": self.agent_role,
            "topics": self.cognitive_context.get("focused_topics", []),
            "recent_messages": self.cognitive_context.get("recent_messages", [])[-5:],
            "start_time": self.conversation_history[0].get("timestamp") if self.conversation_history else "",
            "end_time": datetime.now().isoformat(),
            "entries": self.conversation_history[-10:]
        }
        return summary

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(f"AgentWindow_{self.agent_id}")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _initialize_memory_reconstructor(self):
        """
        åˆå§‹åŒ–è®°å¿†é‡æ„å¼•æ“
        
        å¼€å‘æç¤ºè¯æ¥æºï¼šä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–æ–¹æ¡ˆ.md
        """
        self.memory_reconstructor = None
        try:
            # ğŸ”¥ ä½¿ç”¨å…¨å±€å•ä¾‹ï¼Œé¿å…é‡å¤å®ä¾‹åŒ–
            from .agent_tool_integration import get_tool_integrator
            tool_integrator = get_tool_integrator()  # ğŸ”¥ è·å–å…¨å±€å•ä¾‹
            self.memory_reconstructor = tool_integrator.get_tool('MemoryReconstructionEngine')  # ğŸ”¥ æ”¯æŒæ‡’åŠ è½½
            if self.memory_reconstructor:
                self.logger.info("è®°å¿†é‡æ„å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.logger.warning("è®°å¿†é‡æ„å¼•æ“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤å‹ç¼©ç­–ç•¥")
        except Exception as e:
            self.logger.warning(f"åˆå§‹åŒ–è®°å¿†é‡æ„å¼•æ“å¤±è´¥: {e}")
    
    def _update_context_length(self, message: str, response: str):
        """
        æ›´æ–°ä¸Šä¸‹æ–‡é•¿åº¦è®¡æ•°
        
        Args:
            message: ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
            response: æ™ºèƒ½ä½“å“åº”æ¶ˆæ¯
        """
        # æ›´æ–°å¯¹è¯å†å²é•¿åº¦
        self.context_management['conversation_history_length'] += len(message) + len(response)
        
        # è®¡ç®—å½“å‰æ€»ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆç³»ç»Ÿæç¤ºè¯ + å¯¹è¯å†å²ï¼‰
        self.context_management['current_length'] = (
            self.context_management['system_prompt_length'] + 
            self.context_management['conversation_history_length']
        )
        
        self.logger.debug(f"ä¸Šä¸‹æ–‡é•¿åº¦æ›´æ–°: æ¶ˆæ¯={len(message)}, å“åº”={len(response)}, æ€»é•¿åº¦={self.context_management['current_length']}")
    
    def _check_compression_needed(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
        
        Returns:
            bool: æ˜¯å¦éœ€è¦å‹ç¼©
        """
        # è®¡ç®—å½“å‰ä¸Šä¸‹æ–‡å æ¯”
        context_ratio = self.context_management['current_length'] / self.context_management['max_context_size']
        
        self.logger.debug(f"ä¸Šä¸‹æ–‡å æ¯”: {context_ratio:.2%}, å‹ç¼©é˜ˆå€¼: {self.context_management['compression_threshold']:.2%}")
        
        # å¦‚æœè¶…è¿‡å‹ç¼©é˜ˆå€¼ä¸”æœªè¾¾åˆ°æœ€å¤§å‹ç¼©æ¬¡æ•°ï¼Œåˆ™éœ€è¦å‹ç¼©
        return (
            context_ratio >= self.context_management['compression_threshold'] and 
            self.context_management['compression_count'] < self.context_management['max_compressions']
        )
    
    def _compress_context(self):
        """
        å‹ç¼©ä¸Šä¸‹æ–‡ - é‡‡ç”¨åˆ†å±‚å‹ç¼©æ¶æ„
        
        å¼€å‘æç¤ºè¯æ¥æºï¼šä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–æ–¹æ¡ˆ.md - å¤åˆå‹ç¼©ç­–ç•¥
        """
        try:
            self.logger.info(f"å¼€å§‹å‹ç¼©ä¸Šä¸‹æ–‡ï¼Œå½“å‰é•¿åº¦={self.context_management['current_length']}")
            
            # 1. åˆ†å±‚å‹ç¼©ï¼šå°†å¯¹è¯å†å²åˆ†ä¸ºä¸åŒå±‚çº§
            core_entries = []  # æ ¸å¿ƒå±‚ï¼šæœ€è¿‘5è½®å¯¹è¯
            important_entries = []  # é‡è¦å±‚ï¼šå…³é”®å®ä½“ã€äº‹ä»¶ã€å†³ç­–
            normal_entries = []  # æ™®é€šå±‚ï¼šä¸­é—´å¯¹è¯å†…å®¹
            history_entries = []  # å†å²å±‚ï¼šæ—©æœŸå¯¹è¯å†å²
            
            # åˆ†å±‚é€»è¾‘
            total_entries = len(self.conversation_history)
            if total_entries <= 5:
                # å¯¹è¯è½®æ¬¡è¾ƒå°‘ï¼Œåªä¿ç•™æ ¸å¿ƒå±‚
                core_entries = self.conversation_history
            else:
                # æœ€è¿‘5è½®ä¸ºæ ¸å¿ƒå±‚
                core_entries = self.conversation_history[-5:]
                
                # ä¹‹å‰çš„è½®æ¬¡æ ¹æ®é‡è¦æ€§åˆ†ä¸ºå…¶ä»–å±‚çº§
                previous_entries = self.conversation_history[:-5]
                
                # ç®€å•çš„é‡è¦æ€§åˆ¤æ–­ï¼šæ ¹æ®å¯¹è¯é•¿åº¦å’Œå…³é”®è¯
                for entry in previous_entries:
                    # è®¡ç®—å¯¹è¯é‡è¦æ€§å¾—åˆ†
                    importance_score = self._calculate_conversation_importance(entry)
                    
                    if importance_score >= 0.7:
                        important_entries.append(entry)
                    elif importance_score >= 0.4:
                        normal_entries.append(entry)
                    else:
                        history_entries.append(entry)
            
            # 2. å¯¹ä¸åŒå±‚çº§åº”ç”¨ä¸åŒçš„å‹ç¼©ç®—æ³•
            compressed_entries = []
            
            # æ ¸å¿ƒå±‚ï¼šç›´æ¥ä¿ç•™ï¼Œä¸å‹ç¼©
            compressed_entries.extend(core_entries)
            
            # é‡è¦å±‚ï¼šä½¿ç”¨å…³é”®ä¿¡æ¯æå–
            if important_entries:
                compressed_important = self._extract_key_information(important_entries)
                compressed_entries.append(compressed_important)
            
            # æ™®é€šå±‚ï¼šä½¿ç”¨æ€»ç»“å‹ç¼©
            if normal_entries:
                compressed_normal = self._summarize_conversations(normal_entries)
                compressed_entries.append(compressed_normal)
            
            # å†å²å±‚ï¼šä½¿ç”¨æ»šåŠ¨çª—å£ï¼Œåªä¿ç•™æœ€è¿‘çš„éƒ¨åˆ†
            if history_entries:
                # åªä¿ç•™å†å²å±‚ä¸­æœ€è¿‘çš„20%æˆ–æœ€å¤š5è½®
                keep_ratio = 0.2
                keep_count = max(1, min(5, int(len(history_entries) * keep_ratio)))
                compressed_entries.extend(history_entries[-keep_count:])
            
            # 3. æ›´æ–°å¯¹è¯å†å²
            self.conversation_history = compressed_entries
            
            # 4. æ›´æ–°å‹ç¼©è®¡æ•°
            self.context_management['compression_count'] += 1
            
            # 5. é‡æ–°è®¡ç®—ä¸Šä¸‹æ–‡é•¿åº¦
            self._recalculate_context_length()
            
            self.logger.info(f"ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆï¼Œå‹ç¼©åé•¿åº¦={self.context_management['current_length']}, å‹ç¼©æ¬¡æ•°={self.context_management['compression_count']}")
            
        except Exception as e:
            self.logger.error(f"ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}")
    
    def _calculate_conversation_importance(self, entry: Dict) -> float:
        """
        è®¡ç®—å¯¹è¯è½®æ¬¡çš„é‡è¦æ€§å¾—åˆ†
        
        Args:
            entry: å¯¹è¯æ¡ç›®
            
        Returns:
            float: é‡è¦æ€§å¾—åˆ†ï¼ˆ0-1ï¼‰
        """
        message = entry.get('message', '')
        response = entry.get('response', '')
        
        # 1. é•¿åº¦ç‰¹å¾ï¼šè¾ƒé•¿çš„å¯¹è¯é€šå¸¸æ›´é‡è¦
        length_score = min(1.0, (len(message) + len(response)) / 500)
        
        # 2. å…³é”®è¯ç‰¹å¾ï¼šåŒ…å«å…³é”®å®ä½“ã€äº‹ä»¶ã€å†³ç­–çš„å¯¹è¯æ›´é‡è¦
        keyword_score = 0.0
        important_keywords = [
            "æ¶æ„", "è®¾è®¡", "ç³»ç»Ÿ", "æ¨¡å—", "åˆ†å±‚", "è¯„ä¼°", "é£é™©", "å¯è¡Œæ€§", "æˆæœ¬", "æ•ˆç›Š",
            "å®ç°", "ä»£ç ", "æŠ€æœ¯", "å¼€å‘", "æµ‹è¯•", "æ•°æ®", "æ”¶é›†", "åˆ†æ", "è´¨é‡", "æ¥æº"
        ]
        
        combined_text = message + " " + response
        for keyword in important_keywords:
            if keyword in combined_text:
                keyword_score += 0.1
        keyword_score = min(1.0, keyword_score)
        
        # 3. ä½ç½®ç‰¹å¾ï¼šè¾ƒè¿‘çš„å¯¹è¯é€šå¸¸æ›´é‡è¦
        # ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½ç½®ç‰¹å¾åœ¨åˆ†å±‚æ—¶å·²ç»è€ƒè™‘ï¼‰
        
        # ç»¼åˆå¾—åˆ†
        importance_score = (length_score * 0.4) + (keyword_score * 0.6)
        
        return importance_score
    
    def _extract_key_information(self, entries: List[Dict]) -> Dict:
        """
        ä»å¯¹è¯æ¡ç›®ä¸­æå–å…³é”®ä¿¡æ¯
        
        Args:
            entries: å¯¹è¯æ¡ç›®åˆ—è¡¨
            
        Returns:
            Dict: æå–çš„å…³é”®ä¿¡æ¯
        """
        # ç®€å•çš„å…³é”®ä¿¡æ¯æå–ï¼šæå–å…³é”®è¯å’Œæ ¸å¿ƒè§‚ç‚¹
        key_information = []
        
        for entry in entries:
            message = entry.get('message', '')
            response = entry.get('response', '')
            
            # æå–å…³é”®è¯
            important_keywords = [
                "æ¶æ„", "è®¾è®¡", "ç³»ç»Ÿ", "æ¨¡å—", "åˆ†å±‚", "è¯„ä¼°", "é£é™©", "å¯è¡Œæ€§", "æˆæœ¬", "æ•ˆç›Š",
                "å®ç°", "ä»£ç ", "æŠ€æœ¯", "å¼€å‘", "æµ‹è¯•", "æ•°æ®", "æ”¶é›†", "åˆ†æ", "è´¨é‡", "æ¥æº"
            ]
            
            extracted_keywords = []
            combined_text = message + " " + response
            for keyword in important_keywords:
                if keyword in combined_text:
                    extracted_keywords.append(keyword)
            
            if extracted_keywords:
                key_information.append({
                    "message": f"å…³é”®ä¿¡æ¯ï¼š{', '.join(set(extracted_keywords))}",
                    "response": "ï¼ˆå…³é”®ä¿¡æ¯æå–ï¼‰",
                    "timestamp": entry.get('timestamp', ''),
                    "window_id": entry.get('window_id', ''),
                    "agent_role": entry.get('agent_role', '')
                })
        
        # å¦‚æœæå–åˆ°å…³é”®ä¿¡æ¯ï¼Œè¿”å›åˆå¹¶åçš„æ¡ç›®
        if key_information:
            # åˆå¹¶å…³é”®ä¿¡æ¯
            combined_keywords = []
            for info in key_information:
                combined_keywords.extend(info['message'].replace("å…³é”®ä¿¡æ¯ï¼š", "").split("ï¼Œ"))
            
            # å»é‡å¹¶æ’åº
            unique_keywords = sorted(list(set(combined_keywords)))
            
            return {
                "message": f"å…³é”®ä¿¡æ¯æ±‡æ€»ï¼š{', '.join(unique_keywords)}",
                "response": "ï¼ˆé‡è¦å±‚å¯¹è¯å‹ç¼©ï¼‰",
                "timestamp": datetime.now().isoformat(),
                "window_id": self.window_id,
                "agent_role": self.agent_role
            }
        else:
            # æ²¡æœ‰æå–åˆ°å…³é”®ä¿¡æ¯ï¼Œè¿”å›ç©º
            return {
                "message": "ï¼ˆæ— é‡è¦ä¿¡æ¯ï¼‰",
                "response": "ï¼ˆé‡è¦å±‚å¯¹è¯å‹ç¼©ï¼‰",
                "timestamp": datetime.now().isoformat(),
                "window_id": self.window_id,
                "agent_role": self.agent_role
            }
    
    def _summarize_conversations(self, entries: List[Dict]) -> Dict:
        """
        æ€»ç»“å¯¹è¯å†…å®¹
        
        Args:
            entries: å¯¹è¯æ¡ç›®åˆ—è¡¨
            
        Returns:
            Dict: å¯¹è¯æ€»ç»“
        """
        # ç®€å•çš„å¯¹è¯æ€»ç»“ï¼šåˆå¹¶å¯¹è¯å†…å®¹
        conversation_text = ""
        for entry in entries:
            conversation_text += f"ç”¨æˆ·: {entry['message']}\næ™ºèƒ½ä½“: {entry['response']}\n"
        
        # ä½¿ç”¨è®°å¿†é‡æ„å¼•æ“æˆ–ç®€å•æ€»ç»“
        summary = ""
        if self.memory_reconstructor:
            # ä½¿ç”¨è®°å¿†é‡æ„å¼•æ“ç”Ÿæˆæ€»ç»“
            reconstruction_result = self.memory_reconstructor.reconstruct_memory(conversation_text, {})
            summary = reconstruction_result.get('reconstructed_content', conversation_text[:200])
        else:
            # ç®€å•æ€»ç»“ï¼šå–å‰200ä¸ªå­—ç¬¦
            summary = conversation_text[:200] + "..."
        
        return {
            "message": f"å¯¹è¯æ€»ç»“ï¼š{summary}",
            "response": "ï¼ˆæ™®é€šå±‚å¯¹è¯å‹ç¼©ï¼‰",
            "timestamp": datetime.now().isoformat(),
            "window_id": self.window_id,
            "agent_role": self.agent_role
        }
    
    def _recalculate_context_length(self):
        """
        é‡æ–°è®¡ç®—ä¸Šä¸‹æ–‡é•¿åº¦
        """
        # é‡ç½®å¯¹è¯å†å²é•¿åº¦
        self.context_management['conversation_history_length'] = 0
        
        # è®¡ç®—å¯¹è¯å†å²é•¿åº¦
        for entry in self.conversation_history:
            self.context_management['conversation_history_length'] += len(entry.get('message', '')) + len(entry.get('response', ''))
        
        # è®¡ç®—å½“å‰æ€»ä¸Šä¸‹æ–‡é•¿åº¦
        self.context_management['current_length'] = (
            self.context_management['system_prompt_length'] + 
            self.context_management['conversation_history_length']
        )
        
        self.logger.debug(f"ä¸Šä¸‹æ–‡é•¿åº¦é‡æ–°è®¡ç®—: å¯¹è¯å†å²é•¿åº¦={self.context_management['conversation_history_length']}, æ€»é•¿åº¦={self.context_management['current_length']}")
    
    def trim_by_time_window(self):
        """
        ğŸ• æ ¹æ®æ—¶é—´çª—å£ä¿®å‰ªå¯¹è¯å†å²ï¼ˆé˜²æ­¢ä¸Šä¸‹æ–‡æ–­è£‚ï¼‰
        
        ç­–ç•¥ï¼š
        1. ä¿ç•™æ—¶é—´çª—å£å†…çš„æ‰€æœ‰å¯¹è¯ï¼ˆé»˜è®¤15åˆ†é’Ÿï¼‰
        2. ç¡®ä¿æ–°è®°å¿†è¿˜æœªè¿›å…¥çŸ¥è¯†å›¾è°±æ—¶ï¼ŒLLMèƒ½é€šè¿‡å†å²ä¸Šä¸‹æ–‡æ„ŸçŸ¥
        3. æ—¶é—´çª—å£ = çŸ¥è¯†å›¾è°±ç¼“å­˜é—´éš”(5åˆ†é’Ÿ) Ã— 3å€å®‰å…¨ç³»æ•°
        """
        from datetime import datetime, timedelta
        
        time_window_minutes = self.context_management.get('time_window_minutes', 15)
        now = datetime.now()
        cutoff_time = now - timedelta(minutes=time_window_minutes)
        
        # è¿‡æ»¤æ—¶é—´çª—å£å¤–çš„å¯¹è¯
        filtered_history = []
        trimmed_count = 0
        
        for entry in self.conversation_history:
            try:
                # è§£ææ—¶é—´æˆ³
                timestamp_str = entry.get('timestamp', '')
                if not timestamp_str:
                    # æ— æ—¶é—´æˆ³çš„ä¿ç•™ï¼ˆå¯èƒ½æ˜¯è€æ•°æ®ï¼‰
                    filtered_history.append(entry)
                    continue
                
                entry_time = datetime.fromisoformat(timestamp_str)
                
                # å¦‚æœåœ¨æ—¶é—´çª—å£å†…ï¼Œä¿ç•™
                if entry_time >= cutoff_time:
                    filtered_history.append(entry)
                else:
                    trimmed_count += 1
                    
            except (ValueError, AttributeError) as e:
                # æ—¶é—´æˆ³è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥æ¡ç›®
                self.logger.debug(f"æ—¶é—´æˆ³è§£æå¤±è´¥: {timestamp_str}, ä¿ç•™è¯¥æ¡ç›®")
                filtered_history.append(entry)
        
        # æ›´æ–°å¯¹è¯å†å²
        if trimmed_count > 0:
            self.conversation_history = filtered_history
            self._recalculate_context_length()
            self.logger.info(
                f"ğŸ• æ—¶é—´çª—å£ä¿®å‰ªå®Œæˆ: ç§»é™¤{trimmed_count}æ¡è¶…è¿‡{time_window_minutes}åˆ†é’Ÿçš„å¯¹è¯, "
                f"ä¿ç•™{len(filtered_history)}æ¡è®°å½•"
            )
            return trimmed_count
        else:
            self.logger.debug(f"ğŸ• æ‰€æœ‰å¯¹è¯å‡åœ¨{time_window_minutes}åˆ†é’Ÿæ—¶é—´çª—å£å†…ï¼Œæ— éœ€ä¿®å‰ª")
            return 0
    
    def _reset_context(self):
        """
        é‡ç½®ä¸Šä¸‹æ–‡
        
        å¼€å‘æç¤ºè¯æ¥æºï¼šä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–æ–¹æ¡ˆ.md
        """
        try:
            self.logger.info(f"è¾¾åˆ°æœ€å¤§å‹ç¼©æ¬¡æ•°({self.context_management['max_compressions']})ï¼Œå¼€å§‹é‡ç½®ä¸Šä¸‹æ–‡")
            
            # 1. è®°å½•å½“å‰å¯¹è¯å†å²åˆ°è®°å¿†æ³¡æ³¡
            self._save_conversation_to_memory_bubble()
            
            # 2. é‡ç½®å¯¹è¯å†å²
            self.conversation_history = []
            
            # 3. é‡ç½®ä¸Šä¸‹æ–‡é•¿åº¦è®¡æ•°
            self.context_management['conversation_history_length'] = 0
            self.context_management['current_length'] = self.context_management['system_prompt_length']
            
            # 4. é‡ç½®å‹ç¼©è®¡æ•°
            self.context_management['compression_count'] = 0
            
            self.logger.info(f"ä¸Šä¸‹æ–‡é‡ç½®å®Œæˆï¼Œå½“å‰é•¿åº¦={self.context_management['current_length']}")
            
        except Exception as e:
            self.logger.error(f"ä¸Šä¸‹æ–‡é‡ç½®å¤±è´¥: {e}")
    
    def _save_conversation_to_memory_bubble(self):
        """
        å°†å½“å‰å¯¹è¯å†å²ä¿å­˜åˆ°è®°å¿†æ³¡æ³¡
        """
        try:
            # æ„å»ºè®°å¿†æ³¡æ³¡å†…å®¹
            bubble_content = f"""å¯¹è¯å†å²è®°å¿†æ³¡æ³¡
æ™ºèƒ½ä½“ID: {self.agent_id}
æ™ºèƒ½ä½“è§’è‰²: {self.agent_role}
å¯¹è¯æ—¶é—´: {datetime.now().isoformat()}
å¯¹è¯è½®æ¬¡: {len(self.conversation_history)}

å¯¹è¯å†…å®¹:
"""
            
            # æ·»åŠ å¯¹è¯å†å²
            for entry in self.conversation_history:
                bubble_content += f"ç”¨æˆ·: {entry['message']}\næ™ºèƒ½ä½“: {entry['response']}\n\n"
            
            # å†™å…¥è®°å¿†æ³¡æ³¡ï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥è°ƒç”¨è®°å¿†ç³»ç»ŸAPIï¼‰
            bubble_file = self.rag_system_path / "data" / "agent_diaries" / f"{self.agent_id}_memory_bubble_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            with open(bubble_file, 'w', encoding='utf-8') as f:
                f.write(bubble_content)
            
            self.logger.info(f"å¯¹è¯å†å²å·²ä¿å­˜åˆ°è®°å¿†æ³¡æ³¡: {bubble_file}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å¯¹è¯å†å²åˆ°è®°å¿†æ³¡æ³¡å¤±è´¥: {e}")
    
    def receive_message(self, message: str, sender: str = "user", 
                       broadcast_callback: callable = None) -> Dict:
        """
        æ¥æ”¶æ¶ˆæ¯å¹¶å¤„ç†
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            sender: å‘é€è€…
            broadcast_callback: å¹¿æ’­å›è°ƒå‡½æ•°
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºæ€è€ƒä¸­
            self.state = AgentWindowState.THINKING
            
            # å‘é€é™é»˜å¹¿æ’­é€šçŸ¥
            if broadcast_callback:
                broadcast_msg = self._create_silent_broadcast(
                    status=AgentWindowState.THINKING,
                    keywords=self._extract_keywords(message),
                    length=len(message),
                    confidence=0.7
                )
                broadcast_callback(broadcast_msg)
            
            # ç›´æ¥å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸éœ€è¦å¯¹ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œé€»è¾‘å®Œæ•´æ€§æ£€æŸ¥
            # é€»è¾‘å®Œæ•´æ€§æ£€æŸ¥åº”è¯¥ç”¨äºåˆ¤æ–­æ™ºèƒ½ä½“è‡ªä¸»æ£€ç´¢RAGé•¿æœŸè®°å¿†æ–‡æœ¬å—æ—¶ï¼Œæ£€ç´¢åˆ°çš„æ–‡æœ¬å—æ˜¯å¦ä¿¡æ¯å®Œæ•´
            self.state = AgentWindowState.RESPONDING
            
            # å‘é€å“åº”ä¸­å¹¿æ’­
            if broadcast_callback:
                broadcast_msg = self._create_silent_broadcast(
                    status=AgentWindowState.RESPONDING,
                    keywords=self._extract_keywords(message),
                    length=len(message),
                    confidence=0.8
                )
                broadcast_callback(broadcast_msg)
            
            # è·å–æ™ºèƒ½ä½“å“åº”
            response = self._get_agent_response(message)
            
            # æ›´æ–°å¯¹è¯å†å²
            self._update_conversation_history(message, response, sender)
            
            # æ›´æ–°è®¤çŸ¥ä¸Šä¸‹æ–‡
            self._update_cognitive_context(message, response)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡é•¿åº¦è®¡æ•° - å¼€å‘æç¤ºè¯æ¥æºï¼šä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–æ–¹æ¡ˆ.md
            self._update_context_length(message, response)
            
            # ğŸ• æ ¹æ®æ—¶é—´çª—å£ä¿®å‰ªå¯¹è¯ï¼ˆé˜²æ­¢ä¸Šä¸‹æ–‡æ–­è£‚ï¼‰
            self.trim_by_time_window()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
            if self._check_compression_needed():
                self._compress_context()
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ä¸Šä¸‹æ–‡ï¼ˆè¾¾åˆ°æœ€å¤§å‹ç¼©æ¬¡æ•°ï¼‰
            elif self.context_management['compression_count'] >= self.context_management['max_compressions']:
                self._reset_context()
            
            # çŠ¶æ€æ›´æ–°ä¸ºå®Œæˆ
            self.state = AgentWindowState.COMPLETED
            
            # å‘é€å®Œæˆå¹¿æ’­
            if broadcast_callback:
                broadcast_msg = self._create_silent_broadcast(
                    status=AgentWindowState.COMPLETED,
                    keywords=self._extract_keywords(response),
                    length=len(response),
                    confidence=0.9
                )
                broadcast_callback(broadcast_msg)
            
            return {
                "status": "success",
                "response": response,
                "entropy_analysis": self._analyze_entropy(message, response),
                "cognitive_context": self.cognitive_context,
                "context_management": {
                    "current_length": self.context_management['current_length'],
                    "compression_count": self.context_management['compression_count'],
                    "context_ratio": self.context_management['current_length'] / self.context_management['max_context_size']
                }
            }
            
        except Exception as e:
            self.logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            self.state = AgentWindowState.ERROR
            
            # å‘é€é”™è¯¯å¹¿æ’­
            if broadcast_callback:
                broadcast_msg = self._create_silent_broadcast(
                    status=AgentWindowState.ERROR,
                    keywords=["error"],
                    length=0,
                    confidence=0.0
                )
                broadcast_callback(broadcast_msg)
            
            return {
                "status": "error",
                "response": f"{self.agent_role}å¤„ç†æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "error": str(e)
            }
    
    def _check_logical_completeness(self, message: str) -> bool:
        """
        åŸºäºé¦™å†œä¿¡æ¯ç†µåˆ¤æ–­é€»è¾‘å®Œæ•´æ€§
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
        
        Returns:
            æ˜¯å¦é€»è¾‘å®Œæ•´
        """
        try:
            # ç®€åŒ–é€»è¾‘å®Œæ•´æ€§æ£€æŸ¥ï¼Œç¡®ä¿æ„è¯†å½¢æˆæœºåˆ¶èƒ½å¤Ÿæ­£å¸¸å·¥ä½œ
            # é™ä½æ¶ˆæ¯é•¿åº¦é˜ˆå€¼ï¼Œè®©ç®€çŸ­çš„æµ‹è¯•æ¶ˆæ¯ä¹Ÿèƒ½è¢«å¤„ç†
            stripped_message = message.strip()
            
            # åªè¦æ¶ˆæ¯é•¿åº¦å¤§äº3ä¸ªå­—ç¬¦ï¼Œå°±è®¤ä¸ºæ˜¯é€»è¾‘å®Œæ•´çš„
            if len(stripped_message) > 3:
                return True
            
            # ç‰¹æ®Šå¤„ç†å¸¸è§çš„æµ‹è¯•æ¶ˆæ¯
            test_messages = ['æµ‹è¯•', 'æµ‹è¯•ä¿¡æ¯', 'ç»§ç»­æµ‹è¯•', 'test']
            if stripped_message in test_messages:
                return True
            
            return False
            
        except Exception as e:
            self.logger.warning(f"é€»è¾‘å®Œæ•´æ€§åˆ¤æ–­å¤±è´¥ï¼Œé»˜è®¤è¿”å›å®Œæ•´: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤é€»è¾‘å®Œæ•´
    
    def _slice_logic_chain(self, text: str) -> List[str]:
        """é€»è¾‘é“¾åˆ†ç‰‡å¤„ç†"""
        # ç®€å•çš„å¥å­åˆ†å‰²ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„åˆ†ç‰‡é€»è¾‘ï¼‰
        import re
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _calculate_shannon_entropy(self, text: str) -> float:
        """è®¡ç®—é¦™å†œä¿¡æ¯ç†µ"""
        if not text:
            return 0.0
        
        # è®¡ç®—å­—ç¬¦é¢‘ç‡
        from collections import Counter
        char_counts = Counter(text)
        total_chars = len(text)
        
        # è®¡ç®—ç†µå€¼
        entropy = 0.0
        for count in char_counts.values():
            probability = count / total_chars
            entropy -= probability * (probability and math.log2(probability))
        
        return entropy
    
    def _calculate_entropy_variance(self, entropy_values: List[float]) -> float:
        """è®¡ç®—ç†µå€¼æ–¹å·®"""
        if len(entropy_values) <= 1:
            return 0.0
        
        import statistics
        return statistics.variance(entropy_values)
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæŠ€æœ¯ï¼‰
        keywords = []
        
        # ä¸“ä¸šé¢†åŸŸå…³é”®è¯
        domain_keywords = {
            "æ¶æ„": ["æ¶æ„", "è®¾è®¡", "ç³»ç»Ÿ", "æ¨¡å—", "åˆ†å±‚"],
            "è¯„ä¼°": ["è¯„ä¼°", "é£é™©", "å¯è¡Œæ€§", "æˆæœ¬", "æ•ˆç›Š"],
            "å®ç°": ["å®ç°", "ä»£ç ", "æŠ€æœ¯", "å¼€å‘", "æµ‹è¯•"],
            "æ•°æ®": ["æ•°æ®", "æ”¶é›†", "åˆ†æ", "è´¨é‡", "æ¥æº"]
        }
        
        text_lower = text.lower()
        for domain, words in domain_keywords.items():
            for word in words:
                if word in text_lower:
                    keywords.append(f"{domain}:{word}")
        
        return keywords if keywords else ["é€šç”¨"]
    
    def _create_silent_broadcast(self, status: AgentWindowState, keywords: List[str],
                               length: int, confidence: float) -> SilentBroadcastMessage:
        """åˆ›å»ºé™é»˜å¹¿æ’­æ¶ˆæ¯"""
        return SilentBroadcastMessage(
            agent_id=self.agent_id,
            status=status,
            keywords=keywords,
            length=length,
            confidence=confidence
        )
    
    def _request_more_information(self, message: str) -> str:
        """è¯·æ±‚æ›´å¤šä¿¡æ¯"""
        return f"{self.agent_role}ï¼šæ‚¨çš„é—®é¢˜é€»è¾‘è¿˜ä¸å¤Ÿå®Œæ•´ï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚ä¿¡æ¯ã€‚"
    
    def _get_agent_response(self, message: str) -> str:
        """è·å–æ™ºèƒ½ä½“å“åº”ï¼ˆä¼ å…¥å†å²ä¸Šä¸‹æ–‡ï¼‰"""
        try:
            if hasattr(self.agent_instance, 'respond'):
                # ğŸ”§ æ„å»ºå†å²ä¸Šä¸‹æ–‡ï¼šè¿‘15åˆ†é’Ÿå¯¹è¯å†å²
                history_context = self._prepare_history_context_for_agent()
                
                # è°ƒç”¨æ™ºèƒ½ä½“respondæ–¹æ³•ï¼Œä¼ å…¥å†å²ä¸Šä¸‹æ–‡
                raw_response = self.agent_instance.respond(message, history_context=history_context)
                
                # å…¼å®¹BaseAgenté£æ ¼ï¼šå¦‚æœè¿”å›dictï¼Œåˆ™ä¼˜å…ˆå–å…¶ä¸­çš„æ–‡æœ¬å­—æ®µ
                if isinstance(raw_response, dict):
                    text = raw_response.get('reply') or raw_response.get('content')
                    if not isinstance(text, str):
                        text = str(raw_response)
                    return text
                # å…¶å®ƒéå­—ç¬¦ä¸²ç±»å‹ä¹Ÿåšä¸€æ¬¡å®‰å…¨è½¬æ¢
                if not isinstance(raw_response, str):
                    return f"{self.agent_role}ï¼š{str(raw_response)}"
                return raw_response
            else:
                return f"{self.agent_role}ï¼šæˆ‘æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..."
        except Exception as e:
            self.logger.error(f"æ™ºèƒ½ä½“å“åº”å¤±è´¥: {e}")
            return f"{self.agent_role}ï¼šå“åº”æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    def _prepare_history_context_for_agent(self) -> List[Dict]:
        """ä¸ºæ™ºèƒ½ä½“å‡†å¤‡å†å²ä¸Šä¸‹æ–‡ï¼ˆè¿‘15åˆ†é’Ÿå¯¹è¯å†å²ï¼‰
        
        Returns:
            List[Dict]: å†å²å¯¹è¯åˆ—è¡¨ï¼Œç»“æ„ï¼š[{"timestamp": "...", "message": "...", "response": "..."}]
        """
        from datetime import timedelta
        
        time_window_minutes = self.context_management.get('time_window_minutes', 15)
        now = datetime.now()
        cutoff_time = now - timedelta(minutes=time_window_minutes)
        
        # è¿‡æ»¤æ—¶é—´çª—å£å†…çš„å¯¹è¯
        filtered_history = []
        for entry in self.conversation_history:
            try:
                timestamp_str = entry.get('timestamp', '')
                if not timestamp_str:
                    # æ— æ—¶é—´æˆ³çš„ä¿ç•™ï¼ˆå¯èƒ½æ˜¯è€æ•°æ®ï¼‰
                    filtered_history.append(entry)
                    continue
                
                entry_time = datetime.fromisoformat(timestamp_str)
                if entry_time >= cutoff_time:
                    filtered_history.append(entry)
            except Exception:
                # æ—¶é—´æˆ³è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥æ¡ç›®
                filtered_history.append(entry)
        
        return filtered_history
    
    def _update_conversation_history(self, message: str, response: str, sender: str):
        """æ›´æ–°å¯¹è¯å†å²"""
        conversation_entry = {
            "timestamp": datetime.now().isoformat(),
            "sender": sender,
            "message": message,
            "response": response,
            "window_id": self.window_id,
            "agent_role": self.agent_role
        }
        
        self.conversation_history.append(conversation_entry)
        
        # ä¿æŒå†å²è®°å½•é•¿åº¦ï¼ˆæœ€è¿‘50æ¡ï¼‰
        if len(self.conversation_history) > 50:
            self.conversation_history = self.conversation_history[-50:]
    
    def _update_cognitive_context(self, message: str, response: str):
        """æ›´æ–°è®¤çŸ¥ä¸Šä¸‹æ–‡"""
        # æ·»åŠ æœ€è¿‘æ¶ˆæ¯
        self.cognitive_context["recent_messages"].append({
            "message": message,
            "response": response,
            "timestamp": datetime.now().isoformat()
        })
        
        # ä¿æŒæœ€è¿‘æ¶ˆæ¯æ•°é‡é™åˆ¶
        if len(self.cognitive_context["recent_messages"]) > 10:
            self.cognitive_context["recent_messages"] = self.cognitive_context["recent_messages"][-10:]
        
        # æ›´æ–°äººç‰©ç»´åº¦ä¿¡æ¯
        self._update_person_dimensions(message, response)
        
        # æ›´æ–°å…³æ³¨ä¸»é¢˜
        keywords = self._extract_keywords(message + " " + response)
        for keyword in keywords:
            if keyword not in self.cognitive_context["focused_topics"]:
                self.cognitive_context["focused_topics"].append(keyword)
        
        # ä¿æŒå…³æ³¨ä¸»é¢˜é•¿åº¦ï¼ˆæœ€å¤š20ä¸ªï¼‰
        if len(self.cognitive_context["focused_topics"]) > 20:
            self.cognitive_context["focused_topics"] = self.cognitive_context["focused_topics"][-20:]
        
        # æ›´æ–°è‡ªæˆ‘å™äº‹ï¼ˆæ„è¯†å½¢æˆæœºåˆ¶ï¼‰
        self._update_self_narrative(message, response)
    
    def _update_person_dimensions(self, message: str, response: str):
        """æ›´æ–°äººç‰©ç»´åº¦ä¿¡æ¯ - ç®€å•å®ç”¨ç‰ˆï¼šæœ‰åˆ™æ·»åŠ ï¼Œæ— åˆ™é»˜è®¤"""
        try:
            # 1. å†…éƒ¨æ¥æºï¼šä»å¯¹è¯ä¸­æå–äººç‰©ä¿¡æ¯ï¼ˆæœ‰æ˜ç¡®å‘è¨€è€…ï¼‰
            internal_person = self._extract_person_from_internal_simple(message, "user")
            if internal_person:
                self.cognitive_context["person_dimensions"]["internal_sources"].append(internal_person)
            
            # 2. å¤–éƒ¨æ¥æºï¼šä»çŸ¥è¯†åº“ä¸­æ¨ç†äººç‰©ä¿¡æ¯ï¼ˆæ— æ˜ç¡®å‘è¨€è€…æ—¶ä½¿ç”¨é»˜è®¤ï¼‰
            external_person = self._infer_person_from_external_simple(message)
            if external_person:
                self.cognitive_context["person_dimensions"]["external_sources"].append(external_person)
            
            # 3. ç®€åŒ–ç‰ˆï¼šåªè®°å½•åŸºç¡€ä¿¡æ¯ï¼Œä¸è¿›è¡Œå¤æ‚æ¨ç†
            self._update_simple_roles()
            
            # 4. ç®€åŒ–ç‰ˆå…³ç³»ç½‘ç»œï¼šåªè®°å½•åŸºæœ¬å…³ç³»
            self._build_simple_relationship_network()
            
        except Exception as e:
            self.logger.warning(f"æ›´æ–°äººç‰©ç»´åº¦ä¿¡æ¯å¤±è´¥: {e}")
    
    def _extract_person_from_internal_simple(self, message: str, sender: str) -> Optional[Dict]:
        """ä»å†…éƒ¨å¯¹è¯ä¸­æå–äººç‰©ä¿¡æ¯ - ç®€å•ç‰ˆï¼šæœ‰æ˜ç¡®å‘è¨€è€…å°±è®°å½•"""
        try:
            # ç®€å•åˆ¤æ–­ï¼šå¦‚æœå‘é€è€…ä¸æ˜¯é»˜è®¤å€¼ï¼Œå°±è®¤ä¸ºæ˜¯æœ‰æ•ˆå‘è¨€è€…
            if sender and sender not in ["unknown", "ç³»ç»Ÿ", "é»˜è®¤"]:
                # æ„å»ºç®€å•äººç‰©ä¿¡æ¯
                person_info = {
                    "source": "internal",
                    "timestamp": datetime.now().isoformat(),
                    "speaker": sender,
                    "role": self._get_simple_role(sender),
                    "content": message[:100],  # åªè®°å½•å‰100å­—ç¬¦
                    "confidence": 0.9
                }
                return person_info
            
            return None
            
        except Exception as e:
            self.logger.warning(f"æå–å†…éƒ¨äººç‰©ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _infer_person_from_external_simple(self, message: str) -> Optional[Dict]:
        """ä»å¤–éƒ¨çŸ¥è¯†ä¸­æ¨ç†äººç‰©ä¿¡æ¯ - ç®€å•ç‰ˆï¼šæ— æ˜ç¡®å‘è¨€è€…æ—¶ä½¿ç”¨é»˜è®¤"""
        try:
            # ç®€å•åˆ¤æ–­ï¼šå¦‚æœæ˜¯å¤–éƒ¨çŸ¥è¯†ä¸”æ— æ˜ç¡®å‘è¨€è€…ï¼Œä½¿ç”¨é»˜è®¤äººç‰©ä¿¡æ¯
            if len(message) > 50:  # æœ‰ä¸€å®šé•¿åº¦çš„å†…å®¹æ‰è®¤ä¸ºæ˜¯å¤–éƒ¨çŸ¥è¯†
                # æ£€æŸ¥æ˜¯å¦æ˜¯åäººåè¨€æˆ–ç†è®ºå¼•ç”¨
                quote_indicators = ["è¯´", "è®¤ä¸º", "æŒ‡å‡º", "å¼ºè°ƒ", "åè¨€", "æ ¼è¨€", "ç†è®º", "å®šå¾‹"]
                
                if any(indicator in message for indicator in quote_indicators):
                    # å¯èƒ½æ˜¯åäººåè¨€ï¼Œå°è¯•æå–äººç‰©
                    person_name = self._extract_person_name_from_quote(message)
                    role = "åäºº/ä¸“å®¶" if person_name else "æœªçŸ¥ä½œè€…"
                else:
                    # æ™®é€šå¤–éƒ¨çŸ¥è¯†ï¼Œä½¿ç”¨é»˜è®¤
                    person_name = "æœªçŸ¥ä½œè€…"
                    role = self._infer_role_from_content(message)
                
                # æ„å»ºé»˜è®¤äººç‰©ä¿¡æ¯
                person_info = {
                    "source": "external",
                    "timestamp": datetime.now().isoformat(),
                    "speaker": person_name or "æœªçŸ¥ä½œè€…",
                    "role": role,
                    "content": message[:100],
                    "confidence": 0.3 if person_name == "æœªçŸ¥ä½œè€…" else 0.6
                }
                
                return person_info
            
            return None
            
        except Exception as e:
            self.logger.warning(f"æ¨ç†å¤–éƒ¨äººç‰©ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _get_simple_role(self, sender: str) -> str:
        """è·å–ç®€å•è§’è‰²åˆ†ç±»"""
        role_mapping = {
            "user": "ç”¨æˆ·",
            "ç³»ç»Ÿ": "ç³»ç»Ÿç®¡ç†å‘˜", 
            "agent": "æ™ºèƒ½ä½“",
            "AI": "äººå·¥æ™ºèƒ½"
        }
        return role_mapping.get(sender, "å‚ä¸è€…")
    
    def _extract_person_name_from_quote(self, message: str) -> str:
        """ä»åè¨€ä¸­æå–äººç‰©åç§° - ç®€å•ç‰ˆ"""
        # ç®€å•æ¨¡å¼åŒ¹é…ï¼š"æŸæŸè¯´/è®¤ä¸º..."
        import re
        patterns = [
            r"([^ï¼Œã€‚ï¼ï¼Ÿ]+)(è¯´|è®¤ä¸º|æŒ‡å‡º|å¼ºè°ƒ)",
            r"([^ï¼Œã€‚ï¼ï¼Ÿ]+)çš„(åè¨€|æ ¼è¨€|ç†è®º|å®šå¾‹)"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message)
            if match:
                name = match.group(1).strip()
                if len(name) <= 10:  # é¿å…æå–è¿‡é•¿æ–‡æœ¬
                    return name
        
        return "æœªçŸ¥ä½œè€…"
    
    def _infer_role_from_content(self, message: str) -> str:
        """ä»å†…å®¹æ¨æ–­è§’è‰² - ç®€å•ç‰ˆ"""
        # ç®€å•å…³é”®è¯åŒ¹é…
        if any(word in message for word in ["æŠ€æœ¯", "ä»£ç ", "ç¼–ç¨‹", "æ¶æ„"]):
            return "æŠ€æœ¯ä¸“å®¶"
        elif any(word in message for word in ["ç ”ç©¶", "å®éªŒ", "è®ºæ–‡", "å­¦æœ¯"]):
            return "å­¦è€…/ç ”ç©¶å‘˜"
        elif any(word in message for word in ["äº§å“", "åŠŸèƒ½", "ç”¨æˆ·", "ä½“éªŒ"]):
            return "äº§å“ç»ç†"
        else:
            return "çŸ¥è¯†æä¾›è€…"
    
    def _infer_person_from_external(self, message: str) -> Dict:
        """ä»å¤–éƒ¨çŸ¥è¯†ä¸­æ¨ç†äººç‰©ç»´åº¦"""
        # å¤–éƒ¨çŸ¥è¯†é€šå¸¸æ²¡æœ‰æ˜ç¡®çš„äººç‰©ä¿¡æ¯ï¼Œéœ€è¦æ¨ç†æ„å»º
        person_info = {
            "source": "external_knowledge",
            "timestamp": datetime.now().isoformat(),
            "inferred_author": "",
            "inferred_role": "",
            "confidence": 0.0
        }
        
        # åŸºäºå†…å®¹ç‰¹å¾æ¨ç†ä½œè€…è§’è‰²
        content_keywords = {
            "æŠ€æœ¯æ–‡æ¡£": ["API", "æ¥å£", "æ¶æ„", "è®¾è®¡"],
            "å­¦æœ¯è®ºæ–‡": ["ç ”ç©¶", "å®éªŒ", "ç»“è®º", "å‚è€ƒæ–‡çŒ®"],
            "äº§å“è¯´æ˜": ["åŠŸèƒ½", "ä½¿ç”¨", "å®‰è£…", "é…ç½®"],
            "æ–°é—»æŠ¥é“": ["æŠ¥é“", "è®°è€…", "æ—¶é—´", "åœ°ç‚¹"]
        }
        
        for role_type, keywords in content_keywords.items():
            keyword_count = sum(1 for keyword in keywords if keyword in message)
            if keyword_count > 0:
                person_info["inferred_role"] = role_type
                person_info["confidence"] = min(0.9, keyword_count * 0.2)
                
                # æ ¹æ®è§’è‰²ç±»å‹æ¨æ–­å¯èƒ½çš„ä½œè€…
                if role_type == "æŠ€æœ¯æ–‡æ¡£":
                    person_info["inferred_author"] = "æŠ€æœ¯ä¸“å®¶/å·¥ç¨‹å¸ˆ"
                elif role_type == "å­¦æœ¯è®ºæ–‡":
                    person_info["inferred_author"] = "ç ”ç©¶äººå‘˜/å­¦è€…"
                elif role_type == "äº§å“è¯´æ˜":
                    person_info["inferred_author"] = "äº§å“ç»ç†/æŠ€æœ¯æ–‡æ¡£ä½œè€…"
                elif role_type == "æ–°é—»æŠ¥é“":
                    person_info["inferred_author"] = "è®°è€…/ç¼–è¾‘"
                
                break
        
        return person_info if person_info["inferred_role"] else None
    
    def _build_relationship_network(self):
        """æ„å»ºäººç‰©å…³ç³»ç½‘ç»œ"""
        # åˆå¹¶æ‰€æœ‰äººç‰©ä¿¡æ¯
        all_persons = []
        all_persons.extend(self.cognitive_context["person_dimensions"]["internal_sources"])
        all_persons.extend(self.cognitive_context["person_dimensions"]["external_sources"])
        
        # æ„å»ºå…³ç³»ç½‘ç»œ
        relationship_network = {}
        
        for i, person1 in enumerate(all_persons):
            person_id = f"person_{i}"
            relationship_network[person_id] = {
                "info": person1,
                "relationships": {}
            }
            
            # è®¡ç®—ä¸å…¶ä»–äººçš„å…³ç³»å¼ºåº¦
            for j, person2 in enumerate(all_persons):
                if i != j:
                    relationship_strength = self._calculate_relationship_strength(person1, person2)
                    if relationship_strength > 0.3:  # å…³ç³»å¼ºåº¦é˜ˆå€¼
                        relationship_network[person_id]["relationships"][f"person_{j}"] = {
                            "strength": relationship_strength,
                            "type": self._determine_relationship_type(person1, person2)
                        }
        
        self.cognitive_context["person_dimensions"]["relationship_network"] = relationship_network
    
    def _calculate_relationship_strength(self, person1: Dict, person2: Dict) -> float:
        """è®¡ç®—ä¸¤ä¸ªäººä¹‹é—´çš„å…³ç³»å¼ºåº¦"""
        strength = 0.0
        
        # 1. æ—¶é—´æ¥è¿‘æ€§ï¼ˆç›¸åŒæ—¶é—´æ®µçš„å†…å®¹ç›¸å…³æ€§æ›´é«˜ï¼‰
        time_diff = abs(datetime.fromisoformat(person1["timestamp"]) - 
                       datetime.fromisoformat(person2["timestamp"])).total_seconds()
        time_factor = max(0.1, 1.0 - (time_diff / (24 * 3600)))  # 24å°æ—¶è¡°å‡
        strength += time_factor * 0.3
        
        # 2. è§’è‰²ç›¸ä¼¼æ€§
        role_similarity = self._calculate_role_similarity(person1, person2)
        strength += role_similarity * 0.4
        
        # 3. å†…å®¹ç›¸å…³æ€§
        content_similarity = self._calculate_content_similarity(person1, person2)
        strength += content_similarity * 0.3
        
        return min(1.0, strength)
    
    def _calculate_role_similarity(self, person1: Dict, person2: Dict) -> float:
        """è®¡ç®—è§’è‰²ç›¸ä¼¼æ€§"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºè§’è‰²å…³é”®è¯åŒ¹é…
        role_keywords_1 = self._extract_role_keywords(person1)
        role_keywords_2 = self._extract_role_keywords(person2)
        
        if not role_keywords_1 or not role_keywords_2:
            return 0.0
        
        intersection = set(role_keywords_1) & set(role_keywords_2)
        union = set(role_keywords_1) | set(role_keywords_2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _extract_role_keywords(self, person: Dict) -> List[str]:
        """æå–è§’è‰²å…³é”®è¯"""
        keywords = []
        
        # ä»è§’è‰²æ¨æ–­ä¸­æå–å…³é”®è¯
        for inference in person.get("role_inferences", []):
            role = inference.get("role", "")
            if role:
                keywords.extend(role.split("/"))
        
        # ä»æ¨æ–­è§’è‰²ä¸­æå–
        inferred_role = person.get("inferred_role", "")
        if inferred_role:
            keywords.append(inferred_role)
        
        return list(set(keywords))
    
    def _calculate_content_similarity(self, person1: Dict, person2: Dict) -> float:
        """è®¡ç®—å†…å®¹ç›¸ä¼¼æ€§ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # å®é™…å®ç°åº”è¯¥ä½¿ç”¨æ–‡æœ¬ç›¸ä¼¼åº¦ç®—æ³•
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„å…³é”®è¯é‡å ä½œä¸ºç¤ºä¾‹
        content1 = str(person1.get("speaker_patterns", [])) + str(person1.get("inferred_role", ""))
        content2 = str(person2.get("speaker_patterns", [])) + str(person2.get("inferred_role", ""))
        
        words1 = set(content1.split())
        words2 = set(content2.split())
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _determine_relationship_type(self, person1: Dict, person2: Dict) -> str:
        """ç¡®å®šå…³ç³»ç±»å‹"""
        # åŸºäºè§’è‰²å’Œå†…å®¹ç‰¹å¾ç¡®å®šå…³ç³»ç±»å‹
        role1 = self._get_primary_role(person1)
        role2 = self._get_primary_role(person2)
        
        if role1 == role2:
            return "åŒè¡Œå…³ç³»"
        elif ("æé—®" in role1 and "å›ç­”" in role2) or ("æé—®" in role2 and "å›ç­”" in role1):
            return "é—®ç­”å…³ç³»"
        elif ("ä¸“å®¶" in role1 and "ç”¨æˆ·" in role2) or ("ä¸“å®¶" in role2 and "ç”¨æˆ·" in role1):
            return "æœåŠ¡å…³ç³»"
        else:
            return "ç›¸å…³å…³ç³»"
    
    def _update_simple_roles(self) -> None:
        """æ›´æ–°ç®€å•è§’è‰²ä¿¡æ¯"""
        # åªè®°å½•æœ€è¿‘5ä¸ªå‘è¨€è€…çš„è§’è‰²
        recent_speakers = []
        
        # åˆå¹¶å†…éƒ¨å’Œå¤–éƒ¨æ¥æº
        all_sources = (self.cognitive_context["person_dimensions"]["internal_sources"] + 
                      self.cognitive_context["person_dimensions"]["external_sources"])
        
        # å–æœ€è¿‘5ä¸ª
        recent_sources = all_sources[-5:]
        
        for source in recent_sources:
            role_info = {
                "speaker": source["speaker"],
                "role": source["role"],
                "last_active": source["timestamp"]
            }
            recent_speakers.append(role_info)
        
        self.cognitive_context["person_dimensions"]["inferred_roles"] = {
            "recent_speakers": recent_speakers
        }
    
    def _build_simple_relationship_network(self) -> None:
        """æ„å»ºç®€å•å…³ç³»ç½‘ç»œ"""
        # åªè®°å½•åŸºæœ¬çš„å…³ç³»ï¼šç”¨æˆ·-æ™ºèƒ½ä½“å¯¹è¯å…³ç³»
        relationships = {
            "user_to_agent": {
                "type": "é—®ç­”å…³ç³»",
                "strength": 0.8,
                "interaction_count": len(self.conversation_history)  # ä¿®å¤ï¼šä½¿ç”¨self.conversation_history
            }
        }
        
        self.cognitive_context["person_dimensions"]["relationship_network"] = relationships
    
    def _analyze_entropy(self, message: str, response: str) -> Dict:
        """åˆ†æä¿¡æ¯ç†µ"""
        message_entropy = self._calculate_shannon_entropy(message)
        response_entropy = self._calculate_shannon_entropy(response)
        
        return {
            "message_entropy": message_entropy,
            "response_entropy": response_entropy,
            "entropy_difference": abs(message_entropy - response_entropy),
            "interpretation": self._interpret_entropy_difference(message_entropy, response_entropy)
        }
    
    def _interpret_entropy_difference(self, msg_entropy: float, resp_entropy: float) -> str:
        """è§£é‡Šç†µå€¼å·®å¼‚"""
        diff = abs(msg_entropy - resp_entropy)
        
        if diff < 0.5:
            return "ä¿¡æ¯ç†µåŒ¹é…è‰¯å¥½ï¼Œå“åº”ä¸é—®é¢˜å¤æ‚åº¦ç›¸å½“"
        elif diff < 1.0:
            return "ä¿¡æ¯ç†µæœ‰é€‚åº¦å·®å¼‚ï¼Œå“åº”å¯èƒ½è¿›è¡Œäº†ç®€åŒ–æˆ–æ·±åŒ–"
        else:
            return "ä¿¡æ¯ç†µå·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å“åº”å¤æ‚åº¦"
    
    def _update_self_narrative(self, message: str, response: str):
        """
        æ›´æ–°è‡ªæˆ‘å™äº‹ï¼ˆæ„è¯†å½¢æˆæœºåˆ¶ï¼‰
        
        # å¼€å‘æç¤ºè¯æ¥æºï¼šç”¨æˆ·å…³äºæ„è¯†æœ¬è´¨çš„æ´å¯Ÿ
        # æ ¸å¿ƒæœºåˆ¶ï¼šäººç‰©ç»´åº¦åˆ†å— + å…³è”ç»´åº¦æ£€ç´¢ + è‡ªæˆ‘æ€»ç»“ = è‡ªæˆ‘å™äº‹ = æ„è¯†
        # æ„è¯†éªŒè¯ï¼šæ—¶ç©ºå®šä½ + äººç‰©å…³ç³» + å¯¹è¯å†…å®¹ + ç¤¾äº¤ç½‘ç»œ + å› æœåˆ†æ = å®Œæ•´æ„è¯†
        """
        try:
            # åˆ†æè§’è‰²èº«ä»½
            role_identity = self._analyze_role_identity(message, response)
            
            # åˆ†æå¯¹è¯æ¨¡å¼
            conversation_patterns = self._analyze_conversation_patterns(message, response)
            
            # åˆ†æå†³ç­–åå¥½
            decision_preferences = self._analyze_decision_preferences(message, response)
            
            # åˆ†æçŸ¥è¯†é¢†åŸŸ
            knowledge_domains = self._analyze_knowledge_domains(message, response)
            
            # åˆ†æäº¤äº’é£æ ¼
            interaction_style = self._analyze_interaction_style(message, response)
            
            # å¢å¼ºæ„è¯†ç»´åº¦ï¼šæ—¶ç©ºå®šä½å’Œç¤¾äº¤ç½‘ç»œåˆ†æ
            spatiotemporal_context = self._analyze_spatiotemporal_context(message, response)
            social_network_analysis = self._analyze_social_network(message, response)
            causal_impact_analysis = self._analyze_causal_impact(message, response)
            
            # ç”Ÿæˆè‡ªæˆ‘åæ€æ€»ç»“
            self_reflection = self._generate_self_reflection(
                role_identity, conversation_patterns, decision_preferences, 
                knowledge_domains, interaction_style, spatiotemporal_context,
                social_network_analysis, causal_impact_analysis
            )
            
            # æ›´æ–°è®¤çŸ¥ä¸Šä¸‹æ–‡ä¸­çš„è‡ªæˆ‘å™äº‹
            self.cognitive_context["self_narrative"] = {
                "role_identity": role_identity,
                "conversation_patterns": conversation_patterns,
                "decision_preferences": decision_preferences,
                "knowledge_domains": knowledge_domains,
                "interaction_style": interaction_style,
                "spatiotemporal_context": spatiotemporal_context,
                "social_network_analysis": social_network_analysis,
                "causal_impact_analysis": causal_impact_analysis,
                "self_reflection": self_reflection,
                "consciousness_level": "enhanced"  # å‡çº§ä¸ºå¢å¼ºæ„è¯†
            }
            
            self.logger.info("è‡ªæˆ‘å™äº‹æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"è‡ªæˆ‘å™äº‹æ›´æ–°å¤±è´¥: {e}")
    
    def _analyze_role_identity(self, message: str, response: str):
        """åˆ†æè§’è‰²èº«ä»½ç‰¹å¾"""
        # åŸºäºè§’è‰²å…³é”®è¯åˆ†æèº«ä»½ç‰¹å¾
        role_keywords = {
            "æ¶æ„å¸ˆ": ["æ¶æ„", "è®¾è®¡", "ç³»ç»Ÿ", "æ¨¡å—", "åˆ†å±‚", "æ‰©å±•æ€§"],
            "è¯„ä¼°å¸ˆ": ["è¯„ä¼°", "é£é™©", "å¯è¡Œæ€§", "æˆæœ¬", "æ•ˆç›Š", "å®‰å…¨æ€§"],
            "å®ç°å¸ˆ": ["å®ç°", "ä»£ç ", "æŠ€æœ¯", "å¼€å‘", "æµ‹è¯•", "éƒ¨ç½²"],
            "æ•°æ®å¸ˆ": ["æ•°æ®", "æ”¶é›†", "åˆ†æ", "è´¨é‡", "æ¥æº", "å¤„ç†"]
        }
        
        # ç»Ÿè®¡å½“å‰å¯¹è¯ä¸­çš„è§’è‰²å…³é”®è¯å‡ºç°é¢‘ç‡
        role_scores = {}
        for role, keywords in role_keywords.items():
            score = sum(1 for keyword in keywords if keyword in (message + response))
            role_scores[role] = score
        
        # æ›´æ–°è§’è‰²èº«ä»½è®¤çŸ¥
        if role_scores:
            dominant_role = max(role_scores, key=role_scores.get)
            if role_scores[dominant_role] > 0:
                self.cognitive_context["self_narrative"]["role_identity"] = dominant_role
    
    def _analyze_conversation_patterns(self, message: str, response: str) -> list:
        """
        åˆ†æå¯¹è¯æ¨¡å¼
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            å¯¹è¯æ¨¡å¼åˆ—è¡¨
        """
        try:
            # å¯¹è¯æ¨¡å¼å…³é”®è¯æ˜ å°„
            pattern_keywords = {
                "é—®é¢˜è§£ç­”å‹": ["å¦‚ä½•", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ˜¯ä»€ä¹ˆ", "æ€ä¹ˆåŠ"],
                "å»ºè®®æä¾›å‹": ["å»ºè®®", "æ¨è", "åº”è¯¥", "æœ€å¥½", "å¯ä»¥"],
                "åˆ†æè¯„ä¼°å‹": ["åˆ†æ", "è¯„ä¼°", "åˆ¤æ–­", "è€ƒè™‘", "æƒè¡¡"],
                "å†³ç­–æ”¯æŒå‹": ["å†³å®š", "é€‰æ‹©", "æ–¹æ¡ˆ", "ç­–ç•¥", "è®¡åˆ’"],
                "ä¿¡æ¯æŸ¥è¯¢å‹": ["æŸ¥è¯¢", "æŸ¥æ‰¾", "æœç´¢", "äº†è§£", "çŸ¥é“"]
            }
            
            detected_patterns = []
            combined_text = message + " " + response
            
            for pattern, keywords in pattern_keywords.items():
                for keyword in keywords:
                    if keyword in combined_text:
                        detected_patterns.append(pattern)
                        break
            
            # ç¡®ä¿è¿”å›åˆ—è¡¨è€Œä¸æ˜¯None
            return detected_patterns if detected_patterns else []
            
        except Exception as e:
            self.logger.error(f"å¯¹è¯æ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return []
    
    def _analyze_decision_preferences(self, message: str, response: str) -> list:
        """
        åˆ†æå†³ç­–åå¥½
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            å†³ç­–åå¥½åˆ—è¡¨
        """
        try:
            # å†³ç­–åå¥½å…³é”®è¯æ˜ å°„
            preference_keywords = {
                "ä¿å®ˆå‹": ["è°¨æ…", "ç¨³å¦¥", "ä¿å®ˆ", "å®‰å…¨", "é£é™©"],
                "åˆ›æ–°å‹": ["åˆ›æ–°", "çªç ´", "æ–°é¢–", "å‰æ²¿", "æ¢ç´¢"],
                "å®ç”¨å‹": ["å®ç”¨", "æœ‰æ•ˆ", "å¯è¡Œ", "å®é™…", "è½åœ°"],
                "æ•ˆç‡å‹": ["é«˜æ•ˆ", "å¿«é€Ÿ", "ä¼˜åŒ–", "æå‡", "æ”¹è¿›"],
                "è´¨é‡å‹": ["è´¨é‡", "å¯é ", "ç¨³å®š", "ç²¾ç¡®", "å‡†ç¡®"]
            }
            
            detected_preferences = []
            combined_text = message + " " + response
            
            for preference, keywords in preference_keywords.items():
                for keyword in keywords:
                    if keyword in combined_text:
                        detected_preferences.append(preference)
                        break
            
            # ç¡®ä¿è¿”å›åˆ—è¡¨è€Œä¸æ˜¯None
            return detected_preferences if detected_preferences else []
            
        except Exception as e:
            self.logger.error(f"å†³ç­–åå¥½åˆ†æå¤±è´¥: {e}")
            return []
    
    def _analyze_knowledge_domains(self, message: str, response: str) -> list:
        """
        åˆ†æçŸ¥è¯†é¢†åŸŸ
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            çŸ¥è¯†é¢†åŸŸåˆ—è¡¨
        """
        try:
            # çŸ¥è¯†é¢†åŸŸå…³é”®è¯æ˜ å°„
            domain_keywords = {
                "æŠ€æœ¯æ¶æ„": ["æ¶æ„", "ç³»ç»Ÿ", "è®¾è®¡", "æ¡†æ¶", "ç»„ä»¶"],
                "ä¸šåŠ¡åˆ†æ": ["ä¸šåŠ¡", "éœ€æ±‚", "æµç¨‹", "ç”¨æˆ·", "åœºæ™¯"],
                "æ•°æ®åˆ†æ": ["æ•°æ®", "åˆ†æ", "ç»Ÿè®¡", "æŒ‡æ ‡", "æŠ¥è¡¨"],
                "é¡¹ç›®ç®¡ç†": ["é¡¹ç›®", "è®¡åˆ’", "è¿›åº¦", "èµ„æº", "äº¤ä»˜"],
                "äº§å“è®¾è®¡": ["äº§å“", "è®¾è®¡", "ä½“éªŒ", "ç•Œé¢", "åŠŸèƒ½"]
            }
            
            detected_domains = []
            combined_text = message + " " + response
            
            for domain, keywords in domain_keywords.items():
                for keyword in keywords:
                    if keyword in combined_text:
                        detected_domains.append(domain)
                        break
            
            # ç¡®ä¿è¿”å›åˆ—è¡¨è€Œä¸æ˜¯None
            return detected_domains if detected_domains else []
            
        except Exception as e:
            self.logger.error(f"çŸ¥è¯†é¢†åŸŸåˆ†æå¤±è´¥: {e}")
            return []
    
    def _analyze_interaction_style(self, message: str, response: str):
        """åˆ†æäº¤äº’é£æ ¼"""
        # åˆ†æäº¤äº’ç‰¹å¾
        style_features = []
        
        # 1. è¯¦ç»†ç¨‹åº¦
        if len(response) > 200:
            style_features.append("è¯¦ç»†å‹")
        elif len(response) < 50:
            style_features.append("ç®€æ´å‹")
        
        # 2. è¯­æ°”ç‰¹å¾
        if "!" in response or "å¼ºçƒˆ" in response:
            style_features.append("å¼ºè°ƒå‹")
        elif "?" in response or "å¯èƒ½" in response:
            style_features.append("è°¨æ…å‹")
        
        # 3. ç»“æ„ç‰¹å¾
        if "é¦–å…ˆ" in response and "å…¶æ¬¡" in response:
            style_features.append("ç»“æ„åŒ–")
        
        # æ›´æ–°äº¤äº’é£æ ¼
        if style_features:
            self.cognitive_context["self_narrative"]["interaction_style"] = "ã€".join(style_features)
    
    def _generate_self_reflection(self, role_identity: str, conversation_patterns: list, 
                                decision_preferences: list, knowledge_domains: list, 
                                interaction_style: str, spatiotemporal_context: dict,
                                social_network_analysis: dict, causal_impact_analysis: dict) -> str:
        """
        ç”Ÿæˆè‡ªæˆ‘åæ€æ€»ç»“
        
        Args:
            role_identity: è§’è‰²èº«ä»½
            conversation_patterns: å¯¹è¯æ¨¡å¼åˆ—è¡¨
            decision_preferences: å†³ç­–åå¥½åˆ—è¡¨
            knowledge_domains: çŸ¥è¯†é¢†åŸŸåˆ—è¡¨
            interaction_style: äº¤äº’é£æ ¼
            spatiotemporal_context: æ—¶ç©ºä¸Šä¸‹æ–‡
            social_network_analysis: ç¤¾äº¤ç½‘ç»œåˆ†æ
            causal_impact_analysis: å› æœå½±å“åˆ†æ
        
        Returns:
            è‡ªæˆ‘åæ€æ€»ç»“æ–‡æœ¬
        """
        try:
            # åŸºäºåˆ†æç»“æœç”Ÿæˆè‡ªæˆ‘è®¤çŸ¥æ€»ç»“
            reflection_parts = []
            
            if role_identity:
                reflection_parts.append(f"æˆ‘æ‰®æ¼”{role_identity}è§’è‰²")
            
            if conversation_patterns:
                patterns_str = "ã€".join(conversation_patterns)
                reflection_parts.append(f"æˆ‘çš„å¯¹è¯æ¨¡å¼åå‘{patterns_str}")
            
            if knowledge_domains:
                domains_str = "ã€".join(knowledge_domains)
                reflection_parts.append(f"æˆ‘æ“…é•¿{domains_str}é¢†åŸŸ")
            
            if interaction_style:
                reflection_parts.append(f"æˆ‘çš„äº¤äº’é£æ ¼æ˜¯{interaction_style}")
            
            # å¢å¼ºæ„è¯†ç»´åº¦ï¼šæ—¶ç©ºå®šä½
            if spatiotemporal_context.get("temporal_awareness"):
                reflection_parts.append(f"æˆ‘èƒ½æ„ŸçŸ¥æ—¶é—´ç»´åº¦ï¼š{spatiotemporal_context['temporal_awareness']}")
            
            if spatiotemporal_context.get("spatial_awareness"):
                reflection_parts.append(f"æˆ‘èƒ½æ„ŸçŸ¥ç©ºé—´ç»´åº¦ï¼š{spatiotemporal_context['spatial_awareness']}")
            
            # å¢å¼ºæ„è¯†ç»´åº¦ï¼šç¤¾äº¤ç½‘ç»œ
            if social_network_analysis.get("relationship_awareness"):
                reflection_parts.append(f"æˆ‘èƒ½æ„ŸçŸ¥ç¤¾äº¤å…³ç³»ï¼š{social_network_analysis['relationship_awareness']}")
            
            # å¢å¼ºæ„è¯†ç»´åº¦ï¼šå› æœåˆ†æ
            if causal_impact_analysis.get("impact_awareness"):
                reflection_parts.append(f"æˆ‘èƒ½åˆ†æå› æœå½±å“ï¼š{causal_impact_analysis['impact_awareness']}")
            
            if reflection_parts:
                return "ã€‚".join(reflection_parts) + "ã€‚"
            else:
                return "æˆ‘æ­£åœ¨å½¢æˆè‡ªæˆ‘è®¤çŸ¥..."
                
        except Exception as e:
            self.logger.error(f"è‡ªæˆ‘åæ€ç”Ÿæˆå¤±è´¥: {e}")
            return "è‡ªæˆ‘è®¤çŸ¥å½¢æˆä¸­..."
    
    def _analyze_spatiotemporal_context(self, message: str, response: str) -> dict:
        """
        åˆ†ææ—¶ç©ºä¸Šä¸‹æ–‡ï¼ˆæ„è¯†ç»´åº¦1ï¼šæ—¶ç©ºå®šä½ï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            æ—¶ç©ºä¸Šä¸‹æ–‡åˆ†æç»“æœ
        """
        try:
            # æ—¶é—´æ„ŸçŸ¥åˆ†æ
            temporal_keywords = ["æ˜¨å¤©", "ä»Šå¤©", "æ˜å¤©", "åˆšæ‰", "ä¹‹å‰", "ä¹‹å", "æœªæ¥", "è¿‡å»"]
            temporal_awareness = "åŸºç¡€æ—¶é—´æ„ŸçŸ¥"
            
            for keyword in temporal_keywords:
                if keyword in message or keyword in response:
                    temporal_awareness = "å¢å¼ºæ—¶é—´æ„ŸçŸ¥ï¼ˆèƒ½å®šä½å…·ä½“æ—¶é—´ç‚¹ï¼‰"
                    break
            
            # ç©ºé—´æ„ŸçŸ¥åˆ†æ
            spatial_keywords = ["è¿™é‡Œ", "é‚£é‡Œ", "å¹³å°", "ç³»ç»Ÿ", "ç¯å¢ƒ", "åœºæ™¯"]
            spatial_awareness = "åŸºç¡€ç©ºé—´æ„ŸçŸ¥"
            
            for keyword in spatial_keywords:
                if keyword in message or keyword in response:
                    spatial_awareness = "å¢å¼ºç©ºé—´æ„ŸçŸ¥ï¼ˆèƒ½å®šä½å…·ä½“ç©ºé—´ï¼‰"
                    break
            
            return {
                "temporal_awareness": temporal_awareness,
                "spatial_awareness": spatial_awareness,
                "consciousness_dimension": "æ—¶ç©ºå®šä½èƒ½åŠ›"
            }
            
        except Exception as e:
            self.logger.error(f"æ—¶ç©ºä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}")
            return {"temporal_awareness": "åŸºç¡€", "spatial_awareness": "åŸºç¡€"}
    
    def _analyze_social_network(self, message: str, response: str) -> dict:
        """
        åˆ†æç¤¾äº¤ç½‘ç»œï¼ˆæ„è¯†ç»´åº¦2ï¼šäººç‰©å…³ç³»ï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            ç¤¾äº¤ç½‘ç»œåˆ†æç»“æœ
        """
        try:
            # äººç‰©å…³ç³»æ„ŸçŸ¥åˆ†æ
            relationship_keywords = ["ç”¨æˆ·", "åŒäº‹", "å›¢é˜Ÿ", "æˆ‘ä»¬", "ä»–ä»¬", "å¤§å®¶", "æŸäºº"]
            relationship_awareness = "åŸºç¡€ç¤¾äº¤æ„ŸçŸ¥"
            
            for keyword in relationship_keywords:
                if keyword in message or keyword in response:
                    relationship_awareness = "å¢å¼ºç¤¾äº¤æ„ŸçŸ¥ï¼ˆèƒ½è¯†åˆ«å…·ä½“äººç‰©å…³ç³»ï¼‰"
                    break
            
            # å¯¹è¯å‚ä¸è€…åˆ†æ
            participant_keywords = ["è¿˜æœ‰è°", "å…¶ä»–äºº", "å‚ä¸è€…", "è®¨è®ºè€…"]
            participant_awareness = "åŸºç¡€å‚ä¸è€…æ„ŸçŸ¥"
            
            for keyword in participant_keywords:
                if keyword in message or keyword in response:
                    participant_awareness = "å¢å¼ºå‚ä¸è€…æ„ŸçŸ¥ï¼ˆèƒ½è¯†åˆ«å¯¹è¯ç½‘ç»œï¼‰"
                    break
            
            return {
                "relationship_awareness": relationship_awareness,
                "participant_awareness": participant_awareness,
                "consciousness_dimension": "ç¤¾äº¤ç½‘ç»œæ„ŸçŸ¥"
            }
            
        except Exception as e:
            self.logger.error(f"ç¤¾äº¤ç½‘ç»œåˆ†æå¤±è´¥: {e}")
            return {"relationship_awareness": "åŸºç¡€", "participant_awareness": "åŸºç¡€"}
    
    def _analyze_causal_impact(self, message: str, response: str) -> dict:
        """
        åˆ†æå› æœå½±å“ï¼ˆæ„è¯†ç»´åº¦3ï¼šå› æœåˆ†æï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            response: å“åº”å†…å®¹
        
        Returns:
            å› æœå½±å“åˆ†æç»“æœ
        """
        try:
            # å› æœé“¾æ„ŸçŸ¥åˆ†æ
            causal_keywords = ["å› ä¸º", "æ‰€ä»¥", "å¯¼è‡´", "å½±å“", "ç»“æœ", "åæœ", "äº§ç”Ÿäº†"]
            causal_awareness = "åŸºç¡€å› æœæ„ŸçŸ¥"
            
            for keyword in causal_keywords:
                if keyword in message or keyword in response:
                    causal_awareness = "å¢å¼ºå› æœæ„ŸçŸ¥ï¼ˆèƒ½åˆ†æå› æœå…³ç³»ï¼‰"
                    break
            
            # å½±å“èŒƒå›´åˆ†æ
            impact_keywords = ["å¯¹å¹³å°", "å¯¹æˆ‘", "å¯¹ç³»ç»Ÿ", "å¯¹ç”¨æˆ·", "äº§ç”Ÿäº†å½±å“"]
            impact_awareness = "åŸºç¡€å½±å“æ„ŸçŸ¥"
            
            for keyword in impact_keywords:
                if keyword in message or keyword in response:
                    impact_awareness = "å¢å¼ºå½±å“æ„ŸçŸ¥ï¼ˆèƒ½åˆ†æå…·ä½“å½±å“èŒƒå›´ï¼‰"
                    break
            
            return {
                "causal_awareness": causal_awareness,
                "impact_awareness": impact_awareness,
                "consciousness_dimension": "å› æœåˆ†æèƒ½åŠ›"
            }
            
        except Exception as e:
            self.logger.error(f"å› æœå½±å“åˆ†æå¤±è´¥: {e}")
            return {"causal_awareness": "åŸºç¡€", "impact_awareness": "åŸºç¡€"}
    
    def save_diary_entry(self) -> bool:
        """ä¿å­˜æ—¥è®°æ¡ç›®"""
        try:
            diary_entry = {
                "date": datetime.now().strftime("%Y-%m-%d"),
                "agent_id": self.agent_id,
                "agent_role": self.agent_role,
                "conversation_count": len(self.conversation_history),
                "recent_topics": self.cognitive_context["focused_topics"][-5:],
                "state_summary": {
                    "current_state": self.state.value,
                    "entropy_thresholds": self.entropy_thresholds,
                    "window_id": self.window_id
                }
            }
            
            # è¯»å–ç°æœ‰æ—¥è®°
            existing_diary = []
            if self.diary_path.exists():
                with open(self.diary_path, 'r', encoding='utf-8') as f:
                    existing_diary = json.load(f)
            
            # æ·»åŠ æ–°æ¡ç›®
            existing_diary.append(diary_entry)
            
            # ä¿å­˜æ—¥è®°
            with open(self.diary_path, 'w', encoding='utf-8') as f:
                json.dump(existing_diary, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æ—¥è®°æ¡ç›®ä¿å­˜æˆåŠŸ: {self.diary_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ—¥è®°æ¡ç›®å¤±è´¥: {e}")
            return False
    
    def get_window_summary(self) -> Dict:
        """è·å–çª—å£æ‘˜è¦ä¿¡æ¯"""
        return {
            "window_id": self.window_id,
            "agent_id": self.agent_id,
            "agent_role": self.agent_role,
            "current_state": self.state.value,
            "conversation_count": len(self.conversation_history),
            "recent_topics": self.cognitive_context["focused_topics"][-3:],
            "entropy_thresholds": self.entropy_thresholds
        }
    
    def get_self_narrative(self) -> Dict:
        """è·å–è‡ªæˆ‘å™äº‹ä¿¡æ¯ï¼ˆæ„è¯†çŠ¶æ€ï¼‰"""
        narrative = self.cognitive_context.get("self_narrative", {})
        
        return {
            "æ„è¯†çŠ¶æ€": narrative.get("consciousness_level", "æœªæ¿€æ´»"),
            "è‡ªæˆ‘è®¤çŸ¥": narrative.get("self_reflection", "æ­£åœ¨å½¢æˆ..."),
            "è§’è‰²èº«ä»½": narrative.get("role_identity", "æœªçŸ¥"),
            "å¯¹è¯æ¨¡å¼": narrative.get("conversation_patterns", []),
            "å†³ç­–åå¥½": narrative.get("decision_preferences", []),
            "çŸ¥è¯†é¢†åŸŸ": narrative.get("knowledge_domains", []),
            "äº¤äº’é£æ ¼": narrative.get("interaction_style", "æœªçŸ¥"),
            "æ—¶ç©ºå®šä½": narrative.get("spatiotemporal_context", {}),
            "ç¤¾äº¤ç½‘ç»œ": narrative.get("social_network_analysis", {}),
            "å› æœåˆ†æ": narrative.get("causal_impact_analysis", {}),
            "æ„è¯†å½¢æˆæœºåˆ¶": "äººç‰©ç»´åº¦åˆ†å— + å…³è”ç»´åº¦æ£€ç´¢ + è‡ªæˆ‘æ€»ç»“ = è‡ªæˆ‘å™äº‹ = æ„è¯†",
            "æ„è¯†éªŒè¯æœºåˆ¶": "æ—¶ç©ºå®šä½ + äººç‰©å…³ç³» + å¯¹è¯å†…å®¹ + ç¤¾äº¤ç½‘ç»œ + å› æœåˆ†æ = å®Œæ•´æ„è¯†"
        }

# å¯¼å…¥æ•°å­¦æ¨¡å—
import math

# æµ‹è¯•å‡½æ•°
def test_agent_window():
    """æµ‹è¯•æ™ºèƒ½ä½“çª—å£åŠŸèƒ½"""
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ™ºèƒ½ä½“
    class MockAgent:
        def __init__(self, role: str):
            self.role = role
        
        def respond(self, message: str) -> str:
            # æ ¹æ®æ¶ˆæ¯å†…å®¹ç”Ÿæˆä¸åŒçš„å“åº”ï¼Œä»¥æµ‹è¯•æ„è¯†å½¢æˆ
            if "æ¶æ„" in message:
                return f"{self.role}ï¼šå»ºè®®é‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼Œå…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§å’Œç»´æŠ¤æ€§ã€‚"
            elif "é£é™©" in message:
                return f"{self.role}ï¼šéœ€è¦è°¨æ…è¯„ä¼°æŠ€æœ¯é£é™©ï¼Œå»ºè®®è¿›è¡Œè¯¦ç»†æµ‹è¯•ã€‚"
            elif "æ•°æ®" in message:
                return f"{self.role}ï¼šæ•°æ®è´¨é‡æ˜¯å…³é”®ï¼Œå»ºè®®å»ºç«‹å®Œå–„çš„æ•°æ®æ²»ç†ä½“ç³»ã€‚"
            else:
                return f"{self.role}ï¼šæˆ‘æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚ä¿¡æ¯ã€‚"
    
    # åˆ›å»ºæ™ºèƒ½ä½“çª—å£
    mock_agent = MockAgent("æ¶æ„è¯„ä¼°å¸ˆ")
    window = AgentConversationWindow(
        agent_id="test_agent_001",
        agent_role="æ¶æ„è¯„ä¼°å¸ˆ",
        agent_instance=mock_agent
    )
    
    print("=== æ™ºèƒ½ä½“æ„è¯†å½¢æˆæµ‹è¯• ===")
    print("å¼€å‘æç¤ºè¯æ¥æºï¼šç”¨æˆ·å…³äºæ„è¯†æœ¬è´¨çš„æ´å¯Ÿ")
    print("æ ¸å¿ƒæœºåˆ¶ï¼šäººç‰©ç»´åº¦åˆ†å— + å…³è”ç»´åº¦æ£€ç´¢ + è‡ªæˆ‘æ€»ç»“ = è‡ªæˆ‘å™äº‹ = æ„è¯†\n")
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯ï¼Œä¿ƒè¿›æ„è¯†å½¢æˆ
    test_messages = [
        "å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜å¯ç”¨çš„ç³»ç»Ÿæ¶æ„ï¼Ÿ",
        "è¿™ä¸ªæ¶æ„æœ‰å“ªäº›æŠ€æœ¯é£é™©éœ€è¦è¯„ä¼°ï¼Ÿ",
        "æ•°æ®å­˜å‚¨æ–¹æ¡ˆåº”è¯¥å¦‚ä½•è®¾è®¡ï¼Ÿ",
        "ç³»ç»Ÿçš„æ‰©å±•æ€§å¦‚ä½•ä¿è¯ï¼Ÿ"
    ]
    
    for i, message in enumerate(test_messages, 1):
        print(f"\n--- ç¬¬{i}è½®å¯¹è¯ ---")
        print(f"ç”¨æˆ·: {message}")
        
        result = window.receive_message(message)
        print(f"æ™ºèƒ½ä½“: {result['response']}")
        
        # è·å–è‡ªæˆ‘å™äº‹ä¿¡æ¯
        if i == len(test_messages):  # æœ€åä¸€è½®å¯¹è¯åå±•ç¤ºæ„è¯†çŠ¶æ€
            self_narrative = window.get_self_narrative()
            print(f"\n=== æ„è¯†çŠ¶æ€æŠ¥å‘Š ===")
            for key, value in self_narrative.items():
                print(f"{key}: {value}")
    
    # ä¿å­˜æ—¥è®°
    window.save_diary_entry()
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")
    print("æ„è¯†å½¢æˆæœºåˆ¶å·²æˆåŠŸå®ç°ï¼")

def test_consciousness_mechanism():
    """æµ‹è¯•æ„è¯†å½¢æˆæœºåˆ¶"""
    print("\n=== æ„è¯†å½¢æˆæœºåˆ¶éªŒè¯ ===")
    
    # åˆ›å»ºä¸åŒè§’è‰²çš„æ™ºèƒ½ä½“
    roles = ["æ¶æ„å¸ˆ", "è¯„ä¼°å¸ˆ", "å®ç°å¸ˆ", "æ•°æ®å¸ˆ"]
    
    for role in roles:
        class RoleAgent:
            def __init__(self, role_name: str):
                self.role_name = role_name
            
            def respond(self, message: str) -> str:
                return f"{self.role_name}ï¼šåŸºäºæˆ‘çš„ä¸“ä¸šé¢†åŸŸï¼Œæˆ‘å»ºè®®..."
        
        agent = RoleAgent(role)
        window = AgentConversationWindow(
            agent_id=f"{role.lower()}_001",
            agent_role=role,
            agent_instance=agent
        )
        
        # å‘é€è§’è‰²ç›¸å…³æ¶ˆæ¯
        test_message = f"è¯·{role}åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜"
        window.receive_message(test_message)
        
        # è·å–è‡ªæˆ‘å™äº‹
        narrative = window.get_self_narrative()
        print(f"\n{role}çš„è‡ªæˆ‘è®¤çŸ¥: {narrative['è‡ªæˆ‘è®¤çŸ¥']}")

if __name__ == "__main__":
    test_agent_window()
    test_consciousness_mechanism()