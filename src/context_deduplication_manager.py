# @self-expose: {"id": "context_deduplication_manager", "name": "Context Deduplication Manager", "type": "component", "version": "1.0.0", "needs": {"deps": ["vector_database", "agent_conversation_window"], "resources": []}, "provides": {"capabilities": ["ä¸Šä¸‹æ–‡å»é‡", "åˆ†å±‚ä¿¡æ¯åŠ è½½", "æ—¶é—´æˆ³è¿‡æ»¤"]}}
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸Šä¸‹æ–‡å»é‡ç®¡ç†å™¨
è§£å†³å†å²äº¤äº’æ•°æ®ä¸å‘é‡åº“æ£€ç´¢ç»“æœçš„é‡å¤ä¿¡æ¯é—®é¢˜

æ ¸å¿ƒç­–ç•¥:
1. ã€æ–°é²œæœŸã€‘0-15åˆ†é’Ÿ: ä»…ä»å†å²ä¸Šä¸‹æ–‡åŠ è½½(åŸå§‹å®Œæ•´å¯¹è¯)
2. ã€è¿‡æ¸¡æœŸã€‘15-30åˆ†é’Ÿ: ä¼˜å…ˆä»å‘é‡åº“æ£€ç´¢,å†å²ä¸Šä¸‹æ–‡ä¿ç•™æœ€è¿‘3-5è½®
3. ã€é•¿æœŸè®°å¿†ã€‘30åˆ†é’Ÿ+: å®Œå…¨ä¾èµ–å‘é‡åº“æ£€ç´¢

å»é‡æ–¹æ³•:
- æ—¶é—´æˆ³å»é‡(é¦–é€‰)
- å†…å®¹å“ˆå¸Œå»é‡(é™çº§)
- å‘é‡åº“æ£€ç´¢æ—¶é—´è¿‡æ»¤(æœ€ä¼˜é›…)
"""

import hashlib
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple

class ContextDeduplicationManager:
    """ä¸Šä¸‹æ–‡å»é‡ç®¡ç†å™¨"""
    
    def __init__(
        self,
        history_window_minutes: int = 15,
        kg_cache_interval_minutes: int = 5
    ):
        """
        åˆå§‹åŒ–å»é‡ç®¡ç†å™¨
        
        Args:
            history_window_minutes: å†å²ä¸Šä¸‹æ–‡æ—¶é—´çª—å£(åˆ†é’Ÿ),é»˜è®¤15åˆ†é’Ÿ
            kg_cache_interval_minutes: çŸ¥è¯†å›¾è°±ç¼“å­˜é—´éš”(åˆ†é’Ÿ),é»˜è®¤5åˆ†é’Ÿ
        """
        self.history_window_minutes = history_window_minutes
        self.kg_cache_interval_minutes = kg_cache_interval_minutes
        self.logger = logging.getLogger(__name__)
    
    def build_deduplicated_context(
        self,
        query: str,
        history_context: List[Dict[str, Any]],
        retrieval_results: Optional[List[Dict[str, Any]]] = None,
        enable_retrieval: bool = True
    ) -> str:
        """
        æ„å»ºå»é‡åçš„ä¸Šä¸‹æ–‡(æ ¸å¿ƒæ–¹æ³•)
        
        ç­–ç•¥:
        1. å†å²ä¸Šä¸‹æ–‡ä¼˜å…ˆ(0-15åˆ†é’Ÿå†…çš„åŸå§‹å¯¹è¯)
        2. å‘é‡åº“æ£€ç´¢è¡¥å……(15åˆ†é’Ÿå¤–çš„é•¿æœŸè®°å¿†)
        3. æ—¶é—´æˆ³å»é‡,é¿å…ä¿¡æ¯é‡å¤
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡(æ¥è‡ªæ—¶é—´çª—å£)
            retrieval_results: å‘é‡åº“æ£€ç´¢ç»“æœ(å¯é€‰)
            enable_retrieval: æ˜¯å¦å¯ç”¨å‘é‡åº“æ£€ç´¢
        
        Returns:
            å»é‡åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        history_timestamps = set()
        
        # 1. åŠ è½½å†å²ä¸Šä¸‹æ–‡(æ–°é²œæœŸä¿¡æ¯)
        if history_context:
            context_parts.append("## ğŸ“ è¿‘æœŸå¯¹è¯å†å²\n")
            for entry in history_context:
                timestamp_str = entry.get('timestamp', '')
                if timestamp_str:
                    history_timestamps.add(timestamp_str)
                
                message = entry.get('message', '')
                response = entry.get('response', '')
                role = entry.get('agent_role', 'unknown')
                
                context_parts.append(
                    f"[{timestamp_str}] **{role}**: {message}\n"
                    f"â†’ {response}\n"
                )
            
            self.logger.info(
                f"âœ… å†å²ä¸Šä¸‹æ–‡åŠ è½½å®Œæˆ: {len(history_context)}æ¡å¯¹è¯, "
                f"æ—¶é—´çª—å£: {self.history_window_minutes}åˆ†é’Ÿ"
            )
        
        # 2. åŠ è½½å‘é‡åº“æ£€ç´¢ç»“æœ(é•¿æœŸè®°å¿†)
        if enable_retrieval and retrieval_results:
            # æ—¶é—´æˆ³å»é‡
            deduplicated_memories = []
            for memory in retrieval_results:
                mem_timestamp = memory.get('timestamp', '')
                
                # è·³è¿‡å†å²ä¸Šä¸‹æ–‡ä¸­å·²æœ‰çš„è®°å¿†
                if mem_timestamp and mem_timestamp in history_timestamps:
                    continue
                
                deduplicated_memories.append(memory)
            
            if deduplicated_memories:
                context_parts.append("\n## ğŸ§  ç›¸å…³é•¿æœŸè®°å¿†\n")
                for memory in deduplicated_memories:
                    timestamp = memory.get('timestamp', '')
                    content = memory.get('content', '')
                    source = memory.get('source_type', 'unknown')
                    importance = memory.get('importance', 0.5)
                    
                    context_parts.append(
                        f"[{timestamp}] **{source}** (é‡è¦æ€§:{importance:.2f})\n"
                        f"{content}\n"
                    )
                
                self.logger.info(
                    f"âœ… å‘é‡åº“æ£€ç´¢åŠ è½½å®Œæˆ: {len(deduplicated_memories)}æ¡è®°å¿† "
                    f"(å»é‡å,åŸå§‹{len(retrieval_results)}æ¡)"
                )
            else:
                self.logger.info(
                    "âš ï¸ å‘é‡åº“æ£€ç´¢ç»“æœå…¨éƒ¨ä¸å†å²ä¸Šä¸‹æ–‡é‡å¤,å·²è¿‡æ»¤"
                )
        
        return "\n".join(context_parts)
    
    def deduplicate_by_timestamp(
        self,
        history_items: List[Dict[str, Any]],
        retrieval_items: List[Dict[str, Any]]
    ) -> Tuple[List[Dict], List[Dict]]:
        """
        åŸºäºæ—¶é—´æˆ³å»é‡
        
        ç­–ç•¥: ä¼˜å…ˆä¿ç•™å†å²ä¸Šä¸‹æ–‡(æ›´æ–°é²œ),è¿‡æ»¤å‘é‡åº“ä¸­çš„é‡å¤é¡¹
        
        Returns:
            (history_items, deduplicated_retrieval_items)
        """
        history_timestamps = {
            item.get('timestamp', '') 
            for item in history_items 
            if item.get('timestamp')
        }
        
        deduplicated = []
        duplicated_count = 0
        
        for item in retrieval_items:
            timestamp = item.get('timestamp', '')
            if timestamp and timestamp not in history_timestamps:
                deduplicated.append(item)
            else:
                duplicated_count += 1
        
        self.logger.debug(
            f"æ—¶é—´æˆ³å»é‡å®Œæˆ: ä¿ç•™{len(deduplicated)}æ¡, "
            f"è¿‡æ»¤{duplicated_count}æ¡é‡å¤è®°å¿†"
        )
        
        return history_items, deduplicated
    
    def deduplicate_by_content_hash(
        self,
        history_items: List[Dict[str, Any]],
        retrieval_items: List[Dict[str, Any]]
    ) -> List[Tuple[str, Dict[str, Any]]]:
        """
        åŸºäºå†…å®¹å“ˆå¸Œå»é‡(é™çº§æ–¹æ¡ˆ)
        
        ç”¨äºæ—¶é—´æˆ³ä¸å¯ç”¨æˆ–ä¸ç²¾ç¡®çš„åœºæ™¯
        
        Returns:
            List[(source, item)] - sourceä¸º'history'æˆ–'retrieval'
        """
        seen_hashes = set()
        deduplicated = []
        
        # ä¼˜å…ˆå¤„ç†å†å²ä¸Šä¸‹æ–‡(æ›´æ–°é²œ)
        for item in history_items:
            content = item.get('message', '') + item.get('response', '')
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                deduplicated.append(('history', item))
        
        # å†å¤„ç†å‘é‡åº“æ£€ç´¢ç»“æœ
        for item in retrieval_items:
            content = item.get('content', '')
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                deduplicated.append(('retrieval', item))
        
        self.logger.debug(
            f"å†…å®¹å“ˆå¸Œå»é‡å®Œæˆ: ä¿ç•™{len(deduplicated)}æ¡, "
            f"åŸå§‹{len(history_items) + len(retrieval_items)}æ¡"
        )
        
        return deduplicated
    
    def get_retrieval_time_filter(self) -> Dict[str, str]:
        """
        ç”Ÿæˆå‘é‡åº“æ£€ç´¢çš„æ—¶é—´è¿‡æ»¤æ¡ä»¶
        
        ç­–ç•¥: åªæ£€ç´¢å†å²çª—å£å¤–çš„è®°å¿†(é¿å…ä¸å†å²ä¸Šä¸‹æ–‡é‡å¤)
        
        Returns:
            æ—¶é—´è¿‡æ»¤æ¡ä»¶å­—å…¸,æ ¼å¼: {"end_time": "ISOæ—¶é—´æˆ³"}
        """
        cutoff_time = datetime.now() - timedelta(minutes=self.history_window_minutes)
        
        return {
            "end_time": cutoff_time.isoformat()
        }
    
    def analyze_context_statistics(
        self,
        history_context: List[Dict[str, Any]],
        retrieval_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åˆ†æä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯(è°ƒè¯•ç”¨)
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        history_count = len(history_context)
        retrieval_count = len(retrieval_results)
        
        # ç»Ÿè®¡é‡å æ•°é‡
        history_timestamps = {
            item.get('timestamp', '') 
            for item in history_context 
            if item.get('timestamp')
        }
        
        overlap_count = sum(
            1 for item in retrieval_results
            if item.get('timestamp') in history_timestamps
        )
        
        return {
            "history_count": history_count,
            "retrieval_count": retrieval_count,
            "overlap_count": overlap_count,
            "effective_retrieval_count": retrieval_count - overlap_count,
            "total_unique_count": history_count + retrieval_count - overlap_count,
            "overlap_rate": overlap_count / retrieval_count if retrieval_count > 0 else 0.0,
            "history_window_minutes": self.history_window_minutes,
        }


# å…¨å±€å•ä¾‹
_dedup_manager_instance = None

def get_dedup_manager(
    history_window_minutes: int = 15,
    kg_cache_interval_minutes: int = 5
) -> ContextDeduplicationManager:
    """è·å–å»é‡ç®¡ç†å™¨å•ä¾‹"""
    global _dedup_manager_instance
    
    if _dedup_manager_instance is None:
        _dedup_manager_instance = ContextDeduplicationManager(
            history_window_minutes=history_window_minutes,
            kg_cache_interval_minutes=kg_cache_interval_minutes
        )
    
    return _dedup_manager_instance


if __name__ == "__main__":
    # æµ‹è¯•å»é‡åŠŸèƒ½
    logging.basicConfig(level=logging.INFO)
    
    manager = ContextDeduplicationManager(history_window_minutes=15)
    
    # æ¨¡æ‹Ÿå†å²ä¸Šä¸‹æ–‡
    history = [
        {
            "timestamp": "2025-12-09T18:00:00",
            "message": "å¦‚ä½•å®ç°çŸ¥è¯†å›¾è°±æŒä¹…åŒ–?",
            "response": "é‡‡ç”¨åŠé™æ€ç­–ç•¥...",
            "agent_role": "architect"
        },
        {
            "timestamp": "2025-12-09T18:05:00",
            "message": "æ—¶é—´çª—å£åº”è¯¥è®¾ç½®å¤šé•¿?",
            "response": "å»ºè®®15åˆ†é’Ÿ,çŸ¥è¯†å›¾è°±ç¼“å­˜5åˆ†é’ŸÃ—3å€å®‰å…¨ç³»æ•°",
            "agent_role": "architect"
        }
    ]
    
    # æ¨¡æ‹Ÿå‘é‡åº“æ£€ç´¢ç»“æœ(åŒ…å«é‡å¤é¡¹)
    retrieval = [
        {
            "timestamp": "2025-12-09T18:00:00",  # é‡å¤
            "content": "å¦‚ä½•å®ç°çŸ¥è¯†å›¾è°±æŒä¹…åŒ–? é‡‡ç”¨åŠé™æ€ç­–ç•¥...",
            "source_type": "chatroom_interaction",
            "importance": 0.8
        },
        {
            "timestamp": "2025-12-09T17:30:00",  # ä¸é‡å¤
            "content": "å‘é‡åº“åº”ä½¿ç”¨Chromaæˆ–FAISS",
            "source_type": "knowledge_base",
            "importance": 0.6
        }
    ]
    
    # æ„å»ºå»é‡ä¸Šä¸‹æ–‡
    context = manager.build_deduplicated_context(
        query="å¦‚ä½•ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½?",
        history_context=history,
        retrieval_results=retrieval
    )
    
    print("=" * 80)
    print("å»é‡åçš„ä¸Šä¸‹æ–‡:")
    print("=" * 80)
    print(context)
    print("=" * 80)
    
    # ç»Ÿè®¡åˆ†æ
    stats = manager.analyze_context_statistics(history, retrieval)
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
