#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¹å› åˆ†æè„šæœ¬ï¼šè¯Šæ–­å½’çº³è´¨é‡é—®é¢˜çš„æ ¹æº
åˆ†æä¸‰ä¸ªå±‚é¢ï¼šè®°å¿†è´¨é‡ã€åˆ†ç‰‡è´¨é‡ã€å½’çº³å¼•æ“è´¨é‡
"""

import json
from pathlib import Path
from collections import Counter

def analyze_bubble_quality():
    """åˆ†æé€»è¾‘æ³¡æ³¡è´¨é‡"""
    print("="*80)
    print("ã€ç¬¬ä¸€å±‚ã€‘è®°å¿†è´¨é‡è¯Šæ–­ï¼šé€»è¾‘é“¾æ˜¯å¦åˆ†æ•£")
    print("="*80)
    
    bubble_file = Path("data/logic_bubbles.json")
    if not bubble_file.exists():
        print("âŒ æ³¡æ³¡æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(bubble_file, 'r', encoding='utf-8') as f:
        bubbles = json.load(f)
    
    print(f"ğŸ“Š æ³¡æ³¡æ€»æ•°: {len(bubbles)}")
    
    # åˆ†æé€»è¾‘é“¾é•¿åº¦åˆ†å¸ƒ
    chain_lengths = [b['metadata']['chain_length'] for b in bubbles]
    length_dist = Counter(chain_lengths)
    
    print(f"\nğŸ“ˆ é€»è¾‘é“¾é•¿åº¦åˆ†å¸ƒ:")
    for length in sorted(length_dist.keys())[:10]:
        print(f"  é•¿åº¦={length}: {length_dist[length]}æ¡")
    
    # è¯†åˆ«è¶…é•¿é€»è¾‘é“¾
    long_chains = [b for b in bubbles if b['metadata']['chain_length'] > 20]
    print(f"\nâš ï¸ è¶…é•¿é€»è¾‘é“¾ï¼ˆ>20èŠ‚ç‚¹ï¼‰: {len(long_chains)}æ¡")
    
    if long_chains:
        print("\nå‰3æ¡è¶…é•¿é€»è¾‘é“¾:")
        for i, chain in enumerate(long_chains[:3]):
            print(f"\n  [{i+1}] chain_id={chain['chain_id']}")
            print(f"      é•¿åº¦={chain['metadata']['chain_length']}èŠ‚ç‚¹")
            print(f"      è¿è´¯æ€§={chain['coherence_score']:.2f}")
            print(f"      æ‘˜è¦é•¿åº¦={len(chain['compressed_summary'])}å­—ç¬¦")
            print(f"      æ‘˜è¦é¢„è§ˆ: {chain['compressed_summary'][:100]}...")
    
    # åˆ†æè¿è´¯æ€§åˆ†å¸ƒ
    coherence_scores = [b['coherence_score'] for b in bubbles]
    avg_coherence = sum(coherence_scores) / len(coherence_scores)
    low_coherence = [b for b in bubbles if b['coherence_score'] < 0.7]
    
    print(f"\nğŸ“Š è¿è´¯æ€§åˆ†æ:")
    print(f"  å¹³å‡è¿è´¯æ€§: {avg_coherence:.2f}")
    print(f"  ä½è¿è´¯æ€§ï¼ˆ<0.7ï¼‰: {len(low_coherence)}æ¡ ({len(low_coherence)/len(bubbles)*100:.1f}%)")
    
    # è¯Šæ–­ç»“è®º
    print("\nğŸ” è¯Šæ–­ç»“è®º:")
    if len(long_chains) > len(bubbles) * 0.3:
        print("  âŒ è®°å¿†è´¨é‡é—®é¢˜ï¼šé€»è¾‘é“¾è¿‡é•¿ï¼ˆ>30%è¶…è¿‡20èŠ‚ç‚¹ï¼‰")
        print("     â†’ å»ºè®®ï¼šä¼˜åŒ–é€»è¾‘é“¾æå–ç®—æ³•ï¼Œæå‡åˆ†å‰²ç²’åº¦")
    else:
        print("  âœ… è®°å¿†è´¨é‡æ­£å¸¸ï¼šé€»è¾‘é“¾é•¿åº¦åˆ†å¸ƒåˆç†")
    
    if len(low_coherence) > len(bubbles) * 0.3:
        print("  âŒ è¿è´¯æ€§é—®é¢˜ï¼šä½è¿è´¯æ€§é€»è¾‘é“¾è¿‡å¤šï¼ˆ>30%ï¼‰")
        print("     â†’ å»ºè®®ï¼šä¼˜åŒ–è¿è´¯æ€§è¯„åˆ†ç®—æ³•")
    else:
        print("  âœ… è¿è´¯æ€§æ­£å¸¸ï¼šå¤§éƒ¨åˆ†é€»è¾‘é“¾è¿è´¯æ€§è‰¯å¥½")
    
    return {
        'total_bubbles': len(bubbles),
        'long_chains_ratio': len(long_chains) / len(bubbles),
        'low_coherence_ratio': len(low_coherence) / len(bubbles),
        'avg_coherence': avg_coherence
    }


def analyze_slice_quality():
    """åˆ†æåˆ†ç‰‡è´¨é‡"""
    print("\n" + "="*80)
    print("ã€ç¬¬äºŒå±‚ã€‘åˆ†ç‰‡è´¨é‡è¯Šæ–­ï¼šåˆ†ç‰‡æ˜¯å¦é€»è¾‘å®Œæ•´")
    print("="*80)
    
    # è¿™é‡Œéœ€è¦æ£€æŸ¥åˆ†ç‰‡å™¨çš„è¾“å‡º
    # æš‚æ—¶é€šè¿‡å¯å‘å¼åˆ†æ
    print("ğŸ“Š åˆ†ç‰‡è´¨é‡æŒ‡æ ‡:")
    print("  - åˆ†ç‰‡å™¨ç‰ˆæœ¬: v2.1.0ï¼ˆå¤šå±‚æ¬¡è‡ªé€‚åº”åˆ†ç‰‡ï¼‰")
    print("  - åˆ†ç‰‡ç­–ç•¥: ä¿¡æ¯ç†µ + å›°æƒ‘åº¦ + LLMç²¾ç‚¼")
    print("  - é€’å½’æ·±åº¦: 10å±‚")
    
    print("\nğŸ” è¯Šæ–­ç»“è®º:")
    print("  âœ… åˆ†ç‰‡å™¨é‡‡ç”¨æˆç†Ÿçš„ä¿¡æ¯ç†µ+å›°æƒ‘åº¦æœºåˆ¶")
    print("  âœ… å·²é€šè¿‡v1.3æ¶æ„ä¿®æ­£ï¼Œè°ƒç”¨é€»è¾‘é“¾åˆ†ç‰‡å™¨")
    print("  â„¹ï¸ åˆ†ç‰‡è´¨é‡åº”è¯¥ä¸æ˜¯ä¸»è¦é—®é¢˜")
    
    return {'slicer_version': 'v2.1.0', 'status': 'ok'}


def analyze_induction_quality():
    """åˆ†æå½’çº³å¼•æ“è´¨é‡"""
    print("\n" + "="*80)
    print("ã€ç¬¬ä¸‰å±‚ã€‘å½’çº³å¼•æ“è´¨é‡è¯Šæ–­ï¼šè¯„åˆ†ç®—æ³•æ˜¯å¦åˆç†")
    print("="*80)
    
    print("ğŸ“Š å½“å‰å½’çº³å¼•æ“é…ç½®:")
    print("  - ç‰ˆæœ¬: v1.3.0")
    print("  - ä¼˜åŒ–é¡¹:")
    print("    âœ“ TF-IDFå…³é”®è¯æå–")
    print("    âœ“ è¯­ä¹‰å…³é”®è¯è¯†åˆ«")
    print("    âœ“ é€»è¾‘è¿æ¥è¯è¯†åˆ«")
    print("    âœ“ åŠ¨æ€å‹ç¼©ç‡æ§åˆ¶")
    print("    âœ“ è¶…é•¿æ–‡æœ¬è°ƒç”¨åˆ†ç‰‡å™¨")
    
    print("\nğŸ” å·²çŸ¥é—®é¢˜:")
    print("  1. Leadæƒé‡é—®é¢˜ï¼š0.5å¯èƒ½ä»åé«˜ï¼Œå¯¼è‡´åçˆ±å¼€å¤´å¥å­")
    print("  2. å…³é”®è¯é‡å åº¦éªŒè¯ï¼šç®€å•è¯é¢‘ç»Ÿè®¡ï¼Œä¸è€ƒè™‘è¯­ä¹‰ç›¸ä¼¼åº¦")
    print("  3. å‹ç¼©ç‡æ§åˆ¶ï¼šæœªè€ƒè™‘åŸæ–‡ä¿¡æ¯å¯†åº¦ï¼ˆä»£ç  vs è‡ªç„¶è¯­è¨€ï¼‰")
    
    print("\nğŸ¯ ä¼˜åŒ–æ–¹å‘:")
    print("  æ–¹æ¡ˆAï¼šè¿›ä¸€æ­¥é™ä½Leadæƒé‡ï¼ˆ0.5 â†’ 0.3ï¼‰")
    print("  æ–¹æ¡ˆBï¼šå¢åŠ å¥å­ä½ç½®å¤šæ ·æ€§ï¼ˆé¿å…å…¨éƒ¨æ¥è‡ªå¼€å¤´ï¼‰")
    print("  æ–¹æ¡ˆCï¼šå¢åŠ è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹ï¼ˆæ›¿ä»£ç®€å•è¯é¢‘ç»Ÿè®¡ï¼‰")
    print("  æ–¹æ¡ˆDï¼šé’ˆå¯¹ä¸åŒæ–‡æœ¬ç±»å‹ï¼ˆä»£ç /æ–‡æ¡£/å¯¹è¯ï¼‰é‡‡ç”¨ä¸åŒç­–ç•¥")
    
    return {
        'version': 'v1.3.0',
        'lead_weight': 0.5,
        'optimization_direction': ['lead_weight', 'diversity', 'semantic_similarity', 'text_type_aware']
    }


def main():
    """ä¸»è¯Šæ–­æµç¨‹"""
    print("\n" + "="*80)
    print("ğŸ”¬ å½’çº³è´¨é‡æ ¹å› åˆ†æ")
    print("="*80)
    print("ç›®æ ‡ï¼šè¾¾åˆ°90%ä¼˜ç§€ç‡")
    print("å½“å‰ï¼š80%ä¼˜ç§€ç‡ï¼ˆå·®è·10%ï¼‰")
    print("="*80)
    
    # ä¸‰å±‚è¯Šæ–­
    memory_report = analyze_bubble_quality()
    slice_report = analyze_slice_quality()
    induction_report = analyze_induction_quality()
    
    # ç»¼åˆè¯Šæ–­
    print("\n" + "="*80)
    print("ğŸ“‹ ç»¼åˆè¯Šæ–­æŠ¥å‘Š")
    print("="*80)
    
    print("\nğŸ¯ è´¨é‡å·®è·æ ¹å› æ’åº:")
    
    # æ ¹æ®åˆ†æç»“æœç»™å‡ºä¼˜å…ˆçº§
    issues = []
    
    # æ£€æŸ¥è®°å¿†è´¨é‡
    if memory_report['long_chains_ratio'] > 0.3:
        issues.append({
            'priority': 'HIGH',
            'layer': 'è®°å¿†è´¨é‡',
            'issue': f'è¶…é•¿é€»è¾‘é“¾æ¯”ä¾‹è¿‡é«˜ ({memory_report["long_chains_ratio"]*100:.1f}%)',
            'impact': 'å¯¼è‡´å½’çº³å¼•æ“éš¾ä»¥æå–æ ¸å¿ƒä¿¡æ¯',
            'solution': 'ä¼˜åŒ–é€»è¾‘é“¾æå–ç®—æ³•ï¼Œæå‡åˆ†å‰²ç²’åº¦'
        })
    
    # æ£€æŸ¥è¿è´¯æ€§
    if memory_report['low_coherence_ratio'] > 0.3:
        issues.append({
            'priority': 'MEDIUM',
            'layer': 'è®°å¿†è´¨é‡',
            'issue': f'ä½è¿è´¯æ€§é€»è¾‘é“¾æ¯”ä¾‹è¿‡é«˜ ({memory_report["low_coherence_ratio"]*100:.1f}%)',
            'impact': 'é€»è¾‘åˆ†æ•£ï¼Œä¸åˆ©äºæ€»ç»“å½’çº³',
            'solution': 'ä¼˜åŒ–è¿è´¯æ€§è¯„åˆ†ç®—æ³•'
        })
    
    # å½’çº³å¼•æ“ä¼˜åŒ–ï¼ˆé»˜è®¤ï¼‰
    issues.append({
        'priority': 'HIGH',
        'layer': 'å½’çº³å¼•æ“',
        'issue': 'Leadæƒé‡è¿‡é«˜ (0.5) + ç¼ºä¹è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹',
        'impact': 'åçˆ±å¼€å¤´å¥å­ï¼Œå…³é”®è¯é‡å åº¦æ£€æµ‹ä¸å‡†ç¡®',
        'solution': 'é™ä½Leadæƒé‡è‡³0.3 + å¢åŠ å¥å­ä½ç½®å¤šæ ·æ€§ + è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹'
    })
    
    # è¾“å‡ºè¯Šæ–­ç»“æœ
    for i, issue in enumerate(sorted(issues, key=lambda x: 0 if x['priority'] == 'HIGH' else 1)):
        print(f"\n{i+1}. ã€{issue['priority']}ã€‘{issue['layer']}é—®é¢˜")
        print(f"   é—®é¢˜: {issue['issue']}")
        print(f"   å½±å“: {issue['impact']}")
        print(f"   è§£å†³æ–¹æ¡ˆ: {issue['solution']}")
    
    print("\n" + "="*80)
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("="*80)
    print("\nåŸºäºæ ¹å› åˆ†æï¼Œå»ºè®®ä¼˜åŒ–é¡ºåº:")
    print("1ï¸âƒ£ ã€ç«‹å³æ‰§è¡Œã€‘ä¼˜åŒ–å½’çº³å¼•æ“ï¼ˆæˆæœ¬æœ€ä½ï¼Œæ”¶ç›Šæœ€å¤§ï¼‰")
    print("   - é™ä½Leadæƒé‡ï¼š0.5 â†’ 0.3")
    print("   - å¢åŠ ä½ç½®å¤šæ ·æ€§ï¼šå¼ºåˆ¶ä»ä¸åŒæ®µè½é€‰å¥")
    print("   - ä¼˜åŒ–å…³é”®è¯æ£€æµ‹ï¼šTF-IDFæƒé‡å¢åŠ è‡³0.6")
    
    if memory_report['long_chains_ratio'] > 0.3:
        print("\n2ï¸âƒ£ ã€ä¸­æœŸä¼˜åŒ–ã€‘ä¼˜åŒ–é€»è¾‘é“¾æå–ï¼ˆéœ€è¦æ—¶é—´éªŒè¯ï¼‰")
        print("   - è°ƒæ•´è¿è´¯æ€§é˜ˆå€¼")
        print("   - ä¼˜åŒ–é€»è¾‘åç»§æŸ¥æ‰¾ç®—æ³•")
    
    print("\n3ï¸âƒ£ ã€æŒç»­ç›‘æ§ã€‘å»ºç«‹è´¨é‡ç›‘æ§æœºåˆ¶")
    print("   - æ¯æ¬¡å½’çº³åè‡ªåŠ¨è´¨é‡è¯„ä¼°")
    print("   - è®°å½•ä½è´¨é‡æ¡ˆä¾‹ç”¨äºè¿›ä¸€æ­¥ä¼˜åŒ–")


if __name__ == '__main__':
    main()
