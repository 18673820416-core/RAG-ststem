#!/usr/bin/env python3
# @self-expose: {"id": "test_logic_chain_and_induction", "name": "Logic Chain and Induction Test", "type": "test", "version": "1.0.0", "needs": {"deps": ["mesh_database_interface", "induction_engine"], "resources": []}, "provides": {"capabilities": ["test_logic_chain_extraction", "test_induction_summary", "test_bubble_compression"]}}

"""
é€»è¾‘é“¾æå–ä¸å½’çº³å¼•æ“æµ‹è¯•
- ä»»åŠ¡1ï¼šæµ‹è¯•é€»è¾‘é“¾æå–+æ³¡æ³¡å‹ç¼©
- ä»»åŠ¡2ï¼šæµ‹è¯•å½’çº³å¼•æ“å¯¹ç°æœ‰æ–‡æœ¬å—è¿›è¡Œæ‘˜è¦å½’çº³
- ä»»åŠ¡3ï¼šLLMéªŒè¯å½’çº³æ‘˜è¦è´¨é‡
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.mesh_database_interface import MeshDatabaseInterface
from tools.induction_engine import summarize_topic, extract_events
from datetime import datetime
import json

def test_task1_logic_chain_extraction():
    """ä»»åŠ¡1ï¼šæµ‹è¯•é€»è¾‘é“¾æå–+æ³¡æ³¡å‹ç¼©"""
    print("\n" + "="*80)
    print("ä»»åŠ¡1ï¼šé€»è¾‘é“¾æå– + æ³¡æ³¡å‹ç¼©")
    print("="*80)
    
    # åˆ›å»ºæ¥å£å®ä¾‹
    interface = MeshDatabaseInterface()
    
    # è·å–æ‰€æœ‰è®°å¿†ï¼ˆé™åˆ¶æ•°é‡ä»¥åŠ å¿«æµ‹è¯•ï¼‰
    all_memories = interface.vector_db.search_memories(limit=100)
    print(f"ğŸ“Š è·å–åˆ° {len(all_memories)} æ¡è®°å¿†ç”¨äºæµ‹è¯•")
    
    # æå–é€»è¾‘é“¾
    logic_chains = interface.extract_logic_chain(all_memories)
    print(f"\nâœ… é€»è¾‘é“¾æå–å®Œæˆï¼Œå…± {len(logic_chains)} æ¡é€»è¾‘é“¾")
    
    # æ˜¾ç¤ºå‰3æ¡é€»è¾‘é“¾çš„è¯¦ç»†ä¿¡æ¯
    print("\nğŸ“‹ å‰3æ¡é€»è¾‘é“¾ç¤ºä¾‹ï¼š")
    for i, chain in enumerate(logic_chains[:3]):
        print(f"\n--- é€»è¾‘é“¾ {i+1} ---")
        print(f"Chain ID: {chain['chain_id']}")
        print(f"é•¿åº¦: {chain['length']} æ¡è®°å¿†")
        print(f"è¿è´¯æ€§å¾—åˆ†: {chain['coherence_score']:.3f}")
        print(f"å‹ç¼©æ‘˜è¦: {chain['compressed_summary'][:100]}...")
        print(f"å…³é”®èŠ‚ç‚¹æ•°: {len(chain['key_nodes'])}")
        for node in chain['key_nodes']:
            print(f"  - {node['type']}: {node['content'][:50]}...")
    
    # å‹ç¼©ä¸ºæ³¡æ³¡å­˜å‚¨
    bubble_result = interface.compress_to_bubble(logic_chains)
    print(f"\nâœ… æ³¡æ³¡å‹ç¼©å®Œæˆ")
    print(f"æ–°å¢æ³¡æ³¡: {bubble_result['new_bubbles']}")
    print(f"æ€»æ³¡æ³¡æ•°: {bubble_result['total_bubbles']}")
    print(f"å­˜å‚¨è·¯å¾„: {bubble_result['storage_path']}")
    
    return logic_chains, bubble_result


def test_task2_induction_summary():
    """ä»»åŠ¡2ï¼šä½¿ç”¨å½’çº³å¼•æ“å¯¹ç°æœ‰æ–‡æœ¬å—è¿›è¡Œæ‘˜è¦å½’çº³"""
    print("\n" + "="*80)
    print("ä»»åŠ¡2ï¼šå½’çº³å¼•æ“æ‘˜è¦ç”Ÿæˆ")
    print("="*80)
    
    # åˆ›å»ºæ¥å£å®ä¾‹
    interface = MeshDatabaseInterface()
    
    # è·å–æ‰€æœ‰è®°å¿†ï¼ˆé™åˆ¶æ•°é‡ï¼‰
    all_memories = interface.vector_db.search_memories(limit=50)
    print(f"ğŸ“Š è·å–åˆ° {len(all_memories)} æ¡è®°å¿†ç”¨äºå½’çº³")
    
    # ä½¿ç”¨å½’çº³å¼•æ“ç”Ÿæˆæ‘˜è¦
    induction_results = interface.generate_summaries_with_induction(all_memories, batch_size=20)
    print(f"\nâœ… å½’çº³å¼•æ“å¤„ç†å®Œæˆï¼Œå…± {len(induction_results)} æ¡æ‘˜è¦")
    
    # æ˜¾ç¤ºå‰3æ¡å½’çº³ç»“æœ
    print("\nğŸ“‹ å‰3æ¡å½’çº³æ‘˜è¦ç¤ºä¾‹ï¼š")
    for i, result in enumerate(induction_results[:3]):
        print(f"\n--- å½’çº³ç»“æœ {i+1} ---")
        print(f"è®°å¿†ID: {result['id']}")
        print(f"ä¸»é¢˜æ‘˜è¦: {result['topic_summary'][:100]}...")
        print(f"å…³é”®ç‚¹æ•°é‡: {len(result['key_points'])}")
        if result['key_points']:
            print("å…³é”®ç‚¹:")
            for j, kp in enumerate(result['key_points'][:3]):
                print(f"  {j+1}. {kp[:80]}...")
        print(f"äº‹ä»¶æ•°é‡: {len(result['events'])}")
        if result['events']:
            print("æå–çš„äº‹ä»¶:")
            for j, evt in enumerate(result['events'][:2]):
                print(f"  {j+1}. {evt['snippet'][:80]}...")
    
    return induction_results


def test_task3_quality_verification(induction_results):
    """ä»»åŠ¡3ï¼šLLMéªŒè¯å½’çº³æ‘˜è¦è´¨é‡"""
    print("\n" + "="*80)
    print("ä»»åŠ¡3ï¼šå½’çº³è´¨é‡éªŒè¯ï¼ˆLLMæ£€æŸ¥ï¼‰")
    print("="*80)
    
    # åˆ›å»ºæ¥å£å®ä¾‹
    interface = MeshDatabaseInterface()
    
    # è·å–åŸå§‹è®°å¿†å†…å®¹
    all_memories = interface.vector_db.search_memories(limit=50)
    memory_dict = {m['id']: m for m in all_memories}
    
    # éªŒè¯å½’çº³è´¨é‡
    quality_report = {
        'total_checked': 0,
        'high_quality': 0,
        'medium_quality': 0,
        'low_quality': 0,
        'issues': []
    }
    
    print("\nğŸ” å¼€å§‹è´¨é‡éªŒè¯ï¼ˆæ£€æŸ¥å‰10æ¡ï¼‰...")
    
    for i, result in enumerate(induction_results[:10]):
        memory_id = result['id']
        if memory_id not in memory_dict:
            continue
        
        original = memory_dict[memory_id]
        summary = result['topic_summary']
        key_points = result['key_points']
        
        # è´¨é‡è¯„ä¼°æ ‡å‡†
        quality_score = 0
        issues = []
        
        # 1. æ£€æŸ¥æ‘˜è¦é•¿åº¦æ˜¯å¦åˆç†
        if len(summary) > 0:
            quality_score += 1
        else:
            issues.append("æ‘˜è¦ä¸ºç©º")
        
        # 2. æ£€æŸ¥æ˜¯å¦ä¿ç•™äº†åŸæ–‡çš„å…³é”®ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼šæ£€æŸ¥å…³é”®è¯é‡å ï¼‰
        original_words = set(original['content'].lower().split()[:30])
        summary_words = set(summary.lower().split())
        
        if original_words and summary_words:
            overlap = len(original_words.intersection(summary_words)) / len(original_words)
            if overlap > 0.3:
                quality_score += 2
            elif overlap > 0.15:
                quality_score += 1
            else:
                issues.append(f"å…³é”®è¯é‡å åº¦è¾ƒä½: {overlap:.2%}")
        
        # 3. æ£€æŸ¥å…³é”®ç‚¹æ•°é‡
        if len(key_points) > 0:
            quality_score += 1
        else:
            issues.append("æœªæå–åˆ°å…³é”®ç‚¹")
        
        # 4. æ£€æŸ¥æ‘˜è¦é•¿åº¦ä¸åŸæ–‡æ¯”ä¾‹
        compression_ratio = len(summary) / len(original['content']) if original['content'] else 0
        if 0.1 <= compression_ratio <= 0.5:
            quality_score += 1
        elif compression_ratio > 0.8:
            issues.append(f"å‹ç¼©ç‡è¿‡ä½: {compression_ratio:.2%}")
        elif compression_ratio < 0.05:
            issues.append(f"å‹ç¼©ç‡è¿‡é«˜: {compression_ratio:.2%}")
        
        # è¯„çº§
        quality_report['total_checked'] += 1
        if quality_score >= 4:
            quality_report['high_quality'] += 1
            quality_level = "ä¼˜ç§€"
        elif quality_score >= 3:
            quality_report['medium_quality'] += 1
            quality_level = "è‰¯å¥½"
        else:
            quality_report['low_quality'] += 1
            quality_level = "éœ€è¦æ”¹è¿›"
            quality_report['issues'].append({
                'memory_id': memory_id,
                'quality_score': quality_score,
                'issues': issues,
                'original_length': len(original['content']),
                'summary_length': len(summary)
            })
        
        print(f"[{i+1}] è´¨é‡è¯„ä¼°: {quality_level} (å¾—åˆ†: {quality_score}/5)")
        if issues:
            print(f"    é—®é¢˜: {'; '.join(issues)}")
    
    # è¾“å‡ºæ€»ä½“æŠ¥å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š è´¨é‡éªŒè¯æŠ¥å‘Š")
    print("="*80)
    print(f"æ£€æŸ¥æ€»æ•°: {quality_report['total_checked']}")
    print(f"ä¼˜ç§€: {quality_report['high_quality']} ({quality_report['high_quality']/max(quality_report['total_checked'],1)*100:.1f}%)")
    print(f"è‰¯å¥½: {quality_report['medium_quality']} ({quality_report['medium_quality']/max(quality_report['total_checked'],1)*100:.1f}%)")
    print(f"éœ€è¦æ”¹è¿›: {quality_report['low_quality']} ({quality_report['low_quality']/max(quality_report['total_checked'],1)*100:.1f}%)")
    
    if quality_report['issues']:
        print(f"\nâš ï¸ å‘ç° {len(quality_report['issues'])} ä¸ªè´¨é‡é—®é¢˜:")
        for issue in quality_report['issues'][:3]:
            print(f"\nè®°å¿†ID: {issue['memory_id']}")
            print(f"è´¨é‡å¾—åˆ†: {issue['quality_score']}/5")
            print(f"åŸæ–‡é•¿åº¦: {issue['original_length']} å­—ç¬¦")
            print(f"æ‘˜è¦é•¿åº¦: {issue['summary_length']} å­—ç¬¦")
            print(f"é—®é¢˜åˆ—è¡¨: {'; '.join(issue['issues'])}")
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–å½’çº³å¼•æ“
    low_quality_ratio = quality_report['low_quality'] / max(quality_report['total_checked'], 1)
    
    if low_quality_ratio > 0.3:
        print("\nâŒ ç»“è®ºï¼šå½’çº³å¼•æ“è´¨é‡ä¸ç¬¦åˆé¢„æœŸï¼Œéœ€è¦ä¼˜åŒ–")
        print("å»ºè®®ä¼˜åŒ–æ–¹å‘ï¼š")
        print("1. è°ƒæ•´å¥å­è¯„åˆ†ç®—æ³•çš„æƒé‡å‚æ•°")
        print("2. å¢åŠ é¢†åŸŸå…³é”®è¯è¯†åˆ«")
        print("3. ä¼˜åŒ–å‹ç¼©ç‡æ§åˆ¶é€»è¾‘")
        return False, quality_report
    else:
        print("\nâœ… ç»“è®ºï¼šå½’çº³å¼•æ“è´¨é‡ç¬¦åˆé¢„æœŸ")
        return True, quality_report


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "="*80)
    print("è¯­ä¹‰å‹ç¼©æ–¹æ¡ˆæµ‹è¯•")
    print("="*80)
    print("ä»»åŠ¡1: é€»è¾‘é“¾æå– + æ³¡æ³¡å‹ç¼©")
    print("ä»»åŠ¡2: å½’çº³å¼•æ“æ‘˜è¦ç”Ÿæˆ")
    print("ä»»åŠ¡3: LLMè´¨é‡éªŒè¯")
    print("="*80)
    
    try:
        # ä»»åŠ¡1ï¼šé€»è¾‘é“¾æå–+æ³¡æ³¡å‹ç¼©
        logic_chains, bubble_result = test_task1_logic_chain_extraction()
        
        # ä»»åŠ¡2ï¼šå½’çº³å¼•æ“æ‘˜è¦ç”Ÿæˆ
        induction_results = test_task2_induction_summary()
        
        # ä»»åŠ¡3ï¼šè´¨é‡éªŒè¯
        quality_ok, quality_report = test_task3_quality_verification(induction_results)
        
        # æ€»ç»“
        print("\n" + "="*80)
        print("æµ‹è¯•å®Œæˆæ€»ç»“")
        print("="*80)
        print(f"âœ… ä»»åŠ¡1: æå– {len(logic_chains)} æ¡é€»è¾‘é“¾ï¼Œç”Ÿæˆ {bubble_result['new_bubbles']} ä¸ªæ³¡æ³¡")
        print(f"âœ… ä»»åŠ¡2: ç”Ÿæˆ {len(induction_results)} æ¡å½’çº³æ‘˜è¦")
        print(f"âœ… ä»»åŠ¡3: è´¨é‡éªŒè¯å®Œæˆï¼Œä¼˜ç§€ç‡ {quality_report['high_quality']/max(quality_report['total_checked'],1)*100:.1f}%")
        
        if quality_ok:
            print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œå½’çº³å¼•æ“è´¨é‡åˆæ ¼ï¼")
        else:
            print("\nâš ï¸ å½’çº³å¼•æ“éœ€è¦ä¼˜åŒ–ï¼Œè¯·å‚è€ƒè´¨é‡æŠ¥å‘Šä¸­çš„å»ºè®®")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
