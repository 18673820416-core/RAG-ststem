# 系统维护师：重复实现排查标准流程

## 一、整体目标

**目标**：在不打断业务连续性的前提下，系统性识别并治理“重复实现/代码冗余”风险，防止同一逻辑在多处各自维护，导致行为不一致与维护成本指数级上升。

---

## 二、适用场景

- **文件维度的高风险**：
  - 行数 > 800 的大型/超大文件
  - 核心主体文件或聚合文件：
    - 如 `multi_agent_chatroom.py`、`agent_conversation_window.py`、`agent_tool_integration.py`、`DEVELOPMENT_RULES.md`
  - 经历多轮迭代、频繁修改的历史文件

- **业务维度的高风险**：
  - 涉及多个模块协同的业务链：
    - 例：多智能体聊天记录保存 → 日志持久化 → 历史恢复 → 记忆泡泡写入
  - 职责交叉明显的区域：
    - 例：窗口管理 + 日志记录 + 记忆重构同时出现在多个文件

---

## 三、标准流程分解

### 步骤 1：识别易溃点（高风险文件/业务链）

- **文件侧**：
  - 统计行数，标记：
    - 800–1500 行 → 大文件（重点关注）
    - >1500 行 → 超大文件（必须关注）
  - 判断文件角色：
    - 是否为“聚合逻辑中心”（聊天室、窗口管理器、工具集成器等）
    - 是否承担“全局行为/状态”的调度职责

- **业务链侧**：
  - 以“用户视角需求”为起点，拉出完整链路：
    - 例：用户发消息 → 多智能体协作 → 日志写入 → 历史加载 → 记忆系统入库
  - 列出链路上涉及的所有文件/模块，用于后续跨文件排查。

---

### 步骤 2：构建重复实现检测工具（工具辅助）

- 核心思路：使用脚本对文件做 **代码块相似性扫描**，先找出“可疑重复块”，再人工甄别。
- 关键要点：
  - 使用固定大小的代码块窗口（如 15 行），构建文本哈希/字串索引。
  - 过滤掉：
    - 太短、信息量不足的块（长度 < 100 字符等）
    - 仅为注释/空行的块
  - 输出对于每个文件：
    - **重复块数量**  
    - 每个重复块的 **出现行号列表**

- 注意：  
  - 工具只是“雷达”，不负责做结论；  
  - 工具必须可复用，可对整个 `src/`、`docs/`、`api/` 等目录批量运行。

---

### 步骤 3：人工实证验证与工具调优

- **零信任工具输出**：
  - 第一轮运行结果只视为“提示”，不得直接作为“有问题”的判决依据。
  - 需从工具输出中抽样，对比源码：
    - 是否只是滑动窗口导致的“连续行误报”
    - 是否属于合理的重复结构（如标准化日志前缀、通用注释块）

- **调优方向**：
  - 增加“位置间隔”过滤：
    - 仅当同一块在不同位置间隔 > N 行（如 >5 行）时，才视为“真正的重复候选”。
  - 适当调整块大小 / 长度阈值：
    - 过小 → 噪音多
    - 过大 → 精度不足

- **验证目标**：
  - 工具输出的“重复块数”能基本反映“真实冗余程度”，而不是被大量误报掩盖。
  - 在典型文件（如 `agent_conversation_window.py`）上验证通过后，再推广到全局。

---

### 步骤 4：聚焦人工抽检（文件内 + 跨文件）

- **文件内抽检**：
  - 对于单文件内的高频重复块:
    - 判断是否为“同一业务逻辑被分散复制”：
      - 完整函数/流程是否重复出现
      - 是否有两处都在做同样的合法性校验/状态更新
    - 与“合理复用模式”区分开，例如：
      - 日志格式模板
      - 错误文案片段
      - 通用枚举/配置结构

- **跨文件业务链抽检**：
  - 沿着业务链逐环查看：
    - 是否存在“在 A 文件中做了校验，在 B 文件中又做了一次不同实现的校验”
    - 是否存在“两个不同模块各自实现了一套类似的持久化/恢复逻辑”
  - 特别关注：
    - 和“唯一真相”相关的逻辑（如状态源、主数据源）
    - 和“跨模块协作”相关的协议（如聊天记录格式、记忆泡泡结构）

---

### 步骤 5：结论与改动决策

- **若确认存在重复实现**：
  - 优先执行：
    - 将通用逻辑抽离为工具/基类方法
    - 明确唯一职责归属（谁是“主实现”，谁应调用它）
  - 删除或收敛冗余实现：
    - 确保所有调用方都指向同一实现
    - 在必要时通过自曝光协议/文档说明“唯一真相位置”

- **若确认当前项目重复实现并不严重**：
  - 结论应为：
    - “当前架构/规则在本阶段对重复实现有一定防护效果”
  - 同时保留：
    - 这套排查工具与流程，作为未来迭代的“风险治理方法论”
    - 在新模块/大改动后可再次用于体检

---

### 步骤 6：经验沉淀与防复发

- 将本流程本身写入系统维护师的知识体系中，包括：
  - **触发条件**（何时该跑这套流程）
  - **使用工具**（脚本名称、入口、参数）
  - **典型案例**（某次实际排查的过程与结论）
- 与以下既有原则联动：
  - **零信任原则**：  
    - 对“工具输出”、“自己印象”、“以往经验”都不直接信任，必须实证验证。
  - **问题判定前的人工实证验证原则**：  
    - 任何“可能有问题”的判断，都必须有抽检/对比代码作为支撑。
  - **大型与复杂文件的重复实现检查规范**：  
    - 行数、复杂度、迭代次数 → 作为“风险雷达”的输入，而不是“直接判刑”的依据。

---

## 四、系统维护师工具清单（与本流程相关）

- **重复实现检测工具**：
  - 功能：按块扫描文件，输出重复块位置与数量
  - 用途：快速识别“高疑似重复区域”，供人工复核

- **业务链视图/文件清单工具**（可后续扩展）：
  - 功能：根据某个功能/接口，列出涉及的所有文件与调用链
  - 用途：辅助进行跨文件、一条业务链纵深的重复实现排查
