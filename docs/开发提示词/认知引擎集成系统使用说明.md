# 认知引擎集成系统使用说明

## 系统概述

RAG系统现在集成了两个核心认知引擎：

1. **理性认知引擎** (`src/cognitive_engines/reasoning_engine.py`)
   - 基于理性逻辑四规则（矛盾律、同一律、排中律、充足理由律）
   - 提供纯粹理性的标准答案验证

2. **认知破障引擎** (`src/cognitive_engines/cognitive_barrier_break_engine.py`)
   - 基于心秩序、道秩序、规律同构性检测
   - 验证结论在多个维度的一致性

## 集成演示文件

- `cognitive_engine_integration_demo.py` - 集成系统演示
- 运行方式：`python cognitive_engine_integration_demo.py`

## 使用方法

### 1. 基本使用

```python
from src.cognitive_engines.reasoning_engine import ReasoningEngine
from src.cognitive_engines.cognitive_barrier_break_engine import CognitiveBarrierBreakEngine

# 初始化引擎
reasoning_engine = ReasoningEngine()
cognitive_engine = CognitiveBarrierBreakEngine()

# 理性认知引擎验证
reasoning_premise = {
    "content": {
        "propositions": [
            {
                "premise": "宇宙中存在自组织优化规律",
                "conclusion": "生命是宇宙自组织优化的必然结果",
                "concepts": {"前提": "宇宙中存在自组织优化规律", "结论": "生命是宇宙自组织优化的必然结果"}
            }
        ]
    }
}
reasoning_result = reasoning_engine.reason(reasoning_premise)

# 认知破障引擎验证
reasoning_process = {
    "steps": 2,
    "logic_gaps": 0,
    "reasoning_chain": [
        {"premise": "宇宙中存在自组织优化规律", "conclusion": "中间推理"},
        {"premise": "中间推理", "conclusion": "生命是宇宙自组织优化的必然结果"}
    ]
}
context = {
    "domain": "宇宙学",
    "timestamp": "2025-11-18T15:14:39",
    "source_reliability": 0.8
}
hallucination_result = cognitive_engine.detect_hallucination(
    "生命是宇宙自组织优化的必然结果", reasoning_process, context
)
```

### 2. 集成验证

使用`CognitiveEngineIntegration`类进行集成验证：

```python
from cognitive_engine_integration_demo import CognitiveEngineIntegration

integration_system = CognitiveEngineIntegration()
result = integration_system.integrated_verification(
    "宇宙中存在自组织优化规律", 
    "生命是宇宙自组织优化的必然结果"
)

print(f"综合可信度: {result['confidence']:.2%}")
print(f"幻觉概率: {result['probability']:.2%}")
print(f"建议: {result['suggestions']}")
```

## 权重分配

- **理性认知引擎权重**: 0.6（逻辑推导的可靠性）
- **认知破障引擎权重**: 0.4（多维度验证的可靠性）

## 输出结果

集成验证返回包含以下信息的字典：

- `is_hallucination`: 是否为幻觉（概率 > 0.3）
- `probability`: 幻觉概率
- `confidence`: 综合可信度
- `reasoning_analysis`: 理性认知引擎分析结果
- `hallucination_analysis`: 认知破障引擎分析结果
- `suggestions`: 改进建议列表

## 应用场景

1. **AI对话验证**: 验证AI生成的回答是否合理
2. **知识图谱构建**: 验证新知识的可信度
3. **记忆锚点验证**: 验证记忆锚点的逻辑一致性
4. **智能体决策**: 为智能体提供可信度评估

## 开发提示词来源

本系统的设计思路来源于用户对AI幻觉产生原因的深刻分析，以及认知破障引擎与理性认知引擎协同工作的设计理念。